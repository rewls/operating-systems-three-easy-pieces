= 4 The Abstraction: The Process
:figure-caption: Figure 4.
:imagesdir: images
:source-highlighter: rouge
:table-caption!:
:tabsize: 8
:toc: left

* In this chapter, we discuss one of the most fundamental abstractions that
  the OS provides to users: the *process*.
* The definition of a process, informally, is quite simple: it is a running
  program [V+65,BH70].
* The program itself is a lifeless thing: it just sits there on the disk, a
  bunch of instructions (and maybe some static data), waiting to spring into
  action.
* It is the operating system that takes these bytes and gets them running,
  transforming the program into something useful.

'''

* It turns out that one often wants to run more than one program at once; for
  example, consider your desktop or laptop where you might like to run a web
  browser, mail program, a game, a music player, and so forth.
* In fact, a typical system may be seemingly running tens or even hundreds of
  processes at the same time.
* Doing so makes the system easy to use, as one never need be concerned with
  whether a CPU is available; one simply runs programs.
* Hence our challenge:

.The crux of the problem: How to provide the illusion of many CPUs?
****
* Although there are only a few physical CPUs available, how can the OS
  provide the illusion of a nearly-endless supply of said CPUs?
****

* The OS creates this illusion by *virtualizing* the CPU.
* By running one process, then stopping it and running another, and so forth,
  the OS can promote the illusion that many virtual CPUs exist when in fact
  there is only one physical CPU (or a few).
* This basic technique, known as *time sharing* of the CPU, allows users to
  run as many concurrent processes as they would like; the potential cost is
  performance, as each will run more slowly if the CPU(s) must be shared.

'''

* To implement virtualization of the CPU, and to implement it well, the OS
  will need both some low-level machinery and some high-level intelligence.
* We call the low-level machinery *mechanisms*; mechanisms are low-level
  methods or protocols that implement a needed piece of functionality.
* For example, we'll learn later how to implement a *context switch*, which
  gives the OS the ability to stop running one program and start running
  another on a given CPU; this *time-sharing* mechanism is employed by all
  modern OSes.

.Tip: Use time sharing (and space sharing)
****
* *Time sharing* is a basic technique used by an OS to share a resource.
* By allowing the resource to be used for a little while by one entity, and
  then a little while by another, and so forth, the resource in question
  (e.g., the CPU, or a network link) can be shared by many.
* The counterpart of time sharing is *space sharing*, where a resource is
  divided (in space) among those who wish to use it.
* For example, disk space is naturally a space-shared resource; once a block
  is assigned to a file, it is normally not assigned to another file until the
  user deletes the original file.
****

* On top of these mechanisms resides some of the intelligence in the OS, in
  the form of *policies*.
* Policies are algorithms for making some kind of decision within the OS.
* For example, given a number of possible programs to run on a CPU, which
  program should the OS run?
* A *scheduling policy* in the OS will make this decision, likely using
  historical information (e.g., which program has run more over the last
  minute?), workload knowledge (e.g., what types of programs are run), and
  performance metrics (e.g., is the system optimizing for interactive
  performance, or throughput?) to make its decision.

== 4.1 The Abstraction: A Process

* The abstraction provided by the OS of a running program is something we will
  call a *process*.
* As we said above, a process is simply a running program; at any instant in
  time, we can summarize a process by taking an inventory of the different
  pieces of the system it accesses or affects during the course of its
  execution.

'''

* To understand what constitutes a process, we thus have to understand its
  *machine state*: what a program can read or update when it is running.
* At any given time, what parts of the machine are important to the execution
  of this program?

'''

* One obvious component of machine state that comprises a process is its
  _memory_.
* Instructions lie in memory; the data that the running program reads and
  writes sits in memory as well.
* Thus the memory that the process can address (called its *address space*) is
  part of the process.

'''

* Also part of the process's machine state are _registers_; many instructions
  explicitly read or update registers and thus clearly they are important to
  the execution of the process.

'''

* Note that there are some particularly special registers that form part of
  this machine state.
* For example, the *program counter* (*PC*) (sometimes called the *instruction
  pointer* or *IP*) tells us which instruction of the program will execute
  next; similarly a *stack pointer* and associated *frame pointer* are used to
  manage the stack for function parameters, local variables, and return
  addresses.

.Tip: Separate policy and mechanism
****
* In many operating systems, a common design paradigm is to separate
  high-level policies from their low-level mechanisms [L+75].
* You can think of the mechanism as providing the answer to a _how_ question
  about a system; for example, _how_ does an operating system perform a
  context switch?
* The policy provides the answer to a _which_ question; for example, _which_
  process should the operating system run right now?
* Separating the two allows one easily to change policies without having to
  rethink the mechanism and is thus a form of *modularity*, a general software
  design principle.
****

* Finally, programs often access persistent storage devices too.
* Such _I/O information_ might include a list of the files the process
  currently has open.

== 4.2 Process API

* Though we defer discussion of a real process API until a subsequent chapter,
  here we first give some idea of what must be included in any interface of an
  operating system.
* These APIs, in some form, are available on any modern operating system.

'''

Create::
* An operating system must include some method to create new processes.
* When you type a command into the shell, or double-click on an application
  icon, the OS is invoked to create a new process to run the program you have
  indicated.

Destroy::
* As there is an interface for process creation, systems also provide an
  interface to destroy processes forcefully.
* Of course, many processes will run and just exit by themselves when
  complete; when they don't, however, the user may wish to kill them, and thus
  an interface to halt a runaway process is quite useful.

Wait::
* Sometimes it is useful to wait for a process to stop running; thus some kind
  of waiting interface is often provided.

Miscellaneous Control::
* Other than killing or waiting for a process, there are sometimes other
  controls that are possible.
* For example, most operating systems provide some kind of method to suspend a
  process (stop it from running for a while) and then resume it (continue it
  running).

Status::
* There are usually interfaces to get some status information about a process
  as well, such as how long it has run for, or what state it is in.

== 4.3 Process Creation: A Little More Detail

* One mystery that we should unmask a bit is how programs are transformed into
  processes.
* Specifically, how does the OS get a program up and running?
* How does process creation actually work?

'''

* The first thing that the OS must do to run a program is to *load* its code
  and any static data (e.g., initialized variables) into memory, into the
  address space of the process.
* Programs initially reside on *disk* (or, in some modern systems,
  *flash-based SSDs*) in some kind of *executable format*; thus, the process
  of loading a program and static data into memory requires the OS to read
  those bytes from disk and place them in memory somewhere (as shown in Figure
  4.1).

.{figure-caption} {figure-number}. Loading: From Program To Process
image::figure-04-01.png[]

* In early (or simple) operating systems, the loading process is done
  *eagerly*, i.e., all at once before running the program; modern OSes perform
  the process *lazily*, i.e., by loading pieces of code or data only as they
  are needed during program execution.
* To truly understand how lazy loading of pieces of code and data works,
  you'll have to understand more about the machinery of *paging* and
  *swapping*, topics we'll cover in the future when we discuss the
  virtualization of memory.
* For now, just remember that before running anything, the OS clearly must do
  some work to get the important program bits from disk into memory.

'''

* Once the code and static data are loaded into memory, there are a few other
  things the OS needs to do before running the process.
* Some memory must be allocated for the program's *run-time stack* (or just
  *stack*).
* As you should likely already know, C programs use the stack for local
  variables, function parameters, and return addresses; the OS allocates this
  memory and gives it to the process.
* The OS will also likely initialize the stack with arguments; specifically,
  it will fill in the parameters to the `main()` function, i.e., `argc` and
  the `argv` array.

'''

* The OS may also allocate some memory for the program's *heap*.
* In C programs, the heap is used for explicitly requested
  dynamically-allocated data; programs request such space by calling
  `malloc()` and free it explicitly by calling `free()`.
* The heap is needed for data structures such as linked lists, hash tables,
  trees, and other interesting data structures.
* The heap will be small at first; as the program runs, and requests more
  memory via the `malloc()` library API, the OS may get involved and allocate
  more memory to the process to help satisfy such calls.

'''

* The OS will also do some other initialization tasks, particularly as related
  to input/output (I/O).
* For example, in UNIX systems, each process by default has three open *file
  descriptors*, for standard input, output, and error; these descriptors let
  programs easily read input from the terminal and print output to the screen.
* We'll learn more about I/O, file descriptors, and the like in the third part
  of the book on *persistence*.

'''

* By loading the code and static data into memory, by creating and
  initializing a stack, and by doing other work as related to I/O setup, the
  OS has now (finally) set the stage for program execution.
* It thus has one last task: to start the program running at the entry point,
  namely `main()`.
* By jumping to the `main()` routine (through a specialized mechanism that we
  will discuss next chapter), the OS transfers control of the CPU to the
  newly-created process, and thus the program begins its execution.

== 4.4 Process States

* Now that we have some idea of what a process is (though we will continue to
  refine this notion), and (roughly) how it is created, let us talk about the
  different *states* a process can be in at a given time.
* The notion that a process can be in one of these states arose in early
  computer systems [DV66,V+65].
* In a simplified view, a process can be in one of three states:

'''

Running::
* In the running state, a process is running on a processor.
* This means it is executing instructions.
Ready::
* In the ready state, a process is ready to run but for some reason the OS has
  chosen not to run it at this given moment.
Blocked::
* In the blocked state, a process has performed some kind of operation that
  makes it not ready to run until some other event takes place.
* A common example: when a process initiates an I/O request to a disk, it
  becomes blocked and thus some other process can use the processor.

'''

* If we were to map these states to a graph, we would arrive at the diagram in
  Figure 4.2.
* As you can see in the diagram, a process can be moved between the ready and
  running states at the discretion of the OS.
* Being moved from ready to running means the process has been *scheduled*;
  being moved from running to ready means the process has been *descheduled*.
* Once a process has become blocked (e.g., by initiating an I/O operation),
  the OS will keep it as such until some event occurs (e.g., I/O completion);
  at that point, the process moves to the ready state again (and potentially
  immediately to running again, if the OS so decides).

.Process: State Transitions
image::figure-04-02.png[]

* Let's look at an example of how two processes might transition through some
  of these states.
* First, imagine two processes running, each of which only use the CPU (they
  do no I/O).
* In this case, a trace of the state of each process might look like this
  (Figure 4.3).

:figure-number: {counter:figure-number}
.{figure-caption} {figure-number}. Tracing Process State: CPU Only
[%autowidth]
|===
|Time		|Process~0~	|Process~1~	|Notes

|{counter:i}	|Running	|Ready		|
|{counter:i}	|Running	|Ready		|
|{counter:i}	|Running	|Ready		|
|{counter:i}	|Running	|Ready		|Process~0~ now done
|{counter:i}	|-		|Running	|
|{counter:i}	|-		|Running	|
|{counter:i}	|-		|Running	|
|{counter:i}	|-		|Running	|Process~1~ now done
|===

* In this next example, the first process issues an I/O after running for some
  time.
* At that point, the process is blocked, giving the other process a chance to
  run.
* Figure 4.4 shows a trace of this scenario.

:figure-number: {counter:figure-number}
.{figure-caption} {figure-number}. Tracing Process State: CPU and I/O
[%autowidth]
|===
|Time		|Process~0~	|Process~1~	|Notes

|{counter:i}	|Running	|Ready		|
|{counter:i}	|Running	|Ready		|
|{counter:i}	|Running	|Ready		|Process~0~ initiates I/O
|{counter:i}	|Blocked	|Running	|Process~0~ is blocked,
|{counter:i}	|Blocked	|Running	|so Process~1~ runs
|{counter:i}	|Blocked	|Running	|
|{counter:i}	|Ready		|Running	|I/O done
|{counter:i}	|Ready		|Running	|Process~1~ now done
|{counter:i}	|Running	|-		|
|{counter:i}	|Running	|-		|Process~0~ now done
|===

* More specifically, Process~0~ initiates an I/O and becomes blocked waiting
  for it to complete; processes become blocked, for example, when reading from
  a disk or waiting for a packet from a network.
* The OS recognizes Process~0~ is not using the CPU and starts running
  Process~1~.
* While Process~1~ is running, the I/O completes, moving Process~0~ back to
  ready.
* Finally, Process~1~ finishes, and Process~0~ runs and then is done.

'''

* Note that there are many decisions the OS must make, even in this simple
  example.
* First, the system had to decide to run Process~1~ while Process~0~ issued an
  I/O; doing so improves resource utilization by keeping the CPU busy.
* Second, the system decided not to switch back to Process~0~ when its I/O
  completed; it is not clear if this is a good decision or not.
* What do you think?
* These types of decisions are made by the OS *scheduler*, a topic we will
  discuss a few chapters in the future.

== 4.5 Data Structures

* The OS is a program, and like any program, it has some key data structures
  that track various relevant pieces of information.
* To track the state of each process, for example, the OS likely will keep
  some kind of process list for all processes that are ready and some
  additional information to track which process is currently running.
* The OS must also track, in some way, blocked processes; when an I/O event
  completes, the OS should make sure to wake the correct process and ready it
  to run again.

'''

* Figure 4.5 shows what type of information an OS needs to track about each
  process in the xv6 kernel [CK+08].
* Similar process structures exist in "real" operating systems such as Linux,
  Mac OS X, or Windows; look them up and see how much more complex they are.

:figure-number: {counter:figure-number}
.{figure-caption} {figure-number}. The xv6 Proc Structure
[,c]
----
// the registers xv6 will save and restore
// to stop and subsequently restart a process
struct context {
	int eip;
	int esp;
	int ebx;
	int ecx;
	int edx;
	int esi;
	int edi;
	int ebp;
};

// the different states a process can be in
enum proc_state { UNUSED, EMBRYO, SLEEPING,
	RUNNABLE, RUNNING, ZOMBIE };

// the information xv6 tracks about each process
// including its register context and state
struct proc {
	char *mem;			// Start of process memory
	uint sz;			// Size of process memory
	char *kstack;			// Bottom of kernel stack
					// for this process
	enum proc_state state;		// Process state
	int pid;			// Process ID
	struct proc *parent;		// Parent process
	void *chan;			// If !zero, sleeping on chan
	int killed;			// If !zero, has been killed
	struct file *ofile[NOFILE];	// Open files
	struct inode *cwd;		// Current directory
	struct context context;		// Switch here to run process
	struct trapframe *tf;		// Trap frame for the
					// current interrupt
};
----

* From the figure, you can see a couple of important pieces of information the
  OS tracks about a process.
* The *register context* will hold, for a stopped process, the contents of its
  registers.
* When a process is stopped, its registers will be saved to this memory
  location; by restoring these registers (i.e., placing their values back into
  the actual physical registers), the OS can resume running the process.
* We'll learn more about this technique known as a *context switch* in future
  chapters.

'''

* You can also see from the figure that there are some other states a process
  can be in, beyond running, ready, and blocked.
* Sometimes a system will have an *initial* state that the process is in when
  it is being created.
* Also, a process could be placed in a *final* state where it has exited but
  has not yet been cleaned up (in UNIX-based systems, this is called the
  *zombie* state{empty}footnote:[Yes, the zombie state. Just like real
  zombies, these zombies are relatively easy to kill. However, different
  techniques are usually recommended.]).
* This final state can be useful as it allows other processes (usually the
  *parent* that created the process) to examine the return code of the process
  and see if the just-finished process executed successfully (usually,
  programs return zero in UNIX-based systems when they have accomplished a
  task successfully, and non-zero otherwise).
* When finished, the parent will make one final call (e.g., `wait()`) to wait
  for the completion of the child, and to also indicate to the OS that it can
  clean up any relevant data structures that referred to the now-extinct
  process.

.Aside: Data structure -- the process list
****
* Operating systems are replete with various important *data structures* that
  we will discuss in these notes.
* The *process list* (also called the *task list*) is the first such
  structure.
* It is one of the simpler ones, but certainly any OS that has the ability to
  run multiple programs at once will have something akin to this structure in
  order to keep track of all the running programs in the system.
* Sometimes people refer to the individual structure that stores information
  about a process as a *Process Control Block* (*PCB*), a fancy way of talking
  about a C structure that contains information about each process (also
  sometimes called a *process descriptor*).
****

== 4.6 Summary

* We have introduced the most basic abstraction of the OS: the process.
* It is quite simply viewed as a running program.
* With this conceptual view in mind, we will now move on to the nitty-gritty:
  the low-level mechanisms needed to implement processes, and the higher-level
  policies required to schedule them in an intelligent way.
* By combining mechanisms and policies, we will build up our understanding of
  how an operating system virtualizes the CPU.

.Aside: Key process terms
****
* The *process* is the major OS abstraction of a running program. +
  At any point in time, the process can be described by its state: the
  contents of memory in its *address space*, the contents of CPU registers
  (including the *program counter* and *stack pointer*, among others), and
  information about I/O (such as open files which can be read or written).
* The *process API* consists of calls programs can make related to
  processes. +
  Typically, this includes creation, destruction, and other useful calls.
* Processes exist in one of many different *process states*, including
  running, ready to run, and blocked. +
  Different events (e.g., getting scheduled or descheduled, or waiting for an
  I/O to complete) transition a process from one of these states to the other.
* A *process list* contains information about all processes in the system. +
  Each entry is found in what is sometimes called a *process control block*
  (*PCB*), which is really just a structure that contains information about a
  specific process.
****

== References

[BH70] "The Nucleus of a Multiprogramming System" by Per Brinch Hansen. Communications of the ACM, Volume 13:4, April 1970.::
* This paper introduces one of the first *microkernels* in operating systems
  history, called Nucleus.
* The idea of smaller, more minimal systems is a theme that rears its head
  repeatedly in OS history; it all began with Brinch Hansen's work described
  herein.

[CK+08] "The xv6 Operating System" by Russ Cox, Frans Kaashoek, Robert Morris, Nickolai Zeldovich. From: https://github.com/mit-pdos/xv6-public.::
* The coolest real and little OS in the world.
* Download and play with it to learn more about the details of how operating
  systems actually work.
* We have been using an older version (2012-01-30-1-g1c41342) and hence some
  examples in the book may not match the latest in the source.

[DV66] "Programming Semantics for Multiprogrammed Computations" by Jack B. Dennis, Earl C. Van Horn. Communications of the ACM, Volume 9, Number 3, March 1966.::
* This paper defined many of the early terms and concepts around building
  multiprogrammed systems.

[L+75] "Policy/mechanism separation in Hydra" by R. Levin, E. Cohen, W. Corwin, F. Pollack, W. Wulf. SOSP '75, Austin, Texas, November 1975.::
* An early paper about how to structure operating systems in a research OS
  known as Hydra.
* While Hydra never became a mainstream OS, some of its ideas influenced OS
  designers.

[V+65] "Structure of the Multics Supervisor" by V.A. Vyssotsky, F. J. Corbato, R. M. Graham.  Fall Joint Computer Conference, 1965.::
* An early paper on Multics, which described many of the basic ideas and terms
  that we find in modern systems.
* Some of the vision behind computing as a utility are finally being realized
  in modern cloud systems.

== Homework (Simulation)

* This program, `process-run.py`, allows you to see how process states change
  as programs run and either use the CPU (e.g., perform an add instruction) or
  do I/O (e.g., send a request to a disk and wait for it to complete).
* See the README for details.

=== Overview

* This program, called process-run.py, allows you to see how the state of a
  process state changes as it runs on a CPU.
* As described in the chapter, processes can be in a few different states:
+
....
RUNNING - the process is using the CPU right now
READY   - the process could be using the CPU right now
          but (alas) some other process is
BLOCKED - the process is waiting on I/O
          (e.g., it issued a request to a disk)
DONE    - the process is finished executing
....

* In this homework, we'll see how these process states change as a program
  runs, and thus learn a little bit better how these things work.

'''

* To run the program and get its options, do this:
+
....
prompt> ./process-run.py -h
....

* If this doesn't work, type python before the command, like this:
+
....
prompt> python process-run.py -h
....

* What you should see is this:
+
....
Usage: process-run.py [options]

Options:
  -h, --help            show this help message and exit
  -s SEED, --seed=SEED  the random seed
  -l PROCESS_LIST, --processlist=PROCESS_LIST
                        a comma-separated list of processes to run, in the
                        form X1:Y1,X2:Y2,... where X is the number of
                        instructions that process should run, and Y the
                        chances (from 0 to 100) that an instruction will use
                        the CPU or issue an IO
  -L IO_LENGTH, --iolength=IO_LENGTH
                        how long an IO takes
  -S PROCESS_SWITCH_BEHAVIOR, --switch=PROCESS_SWITCH_BEHAVIOR
                        when to switch between processes: SWITCH_ON_IO,
                        SWITCH_ON_END
  -I IO_DONE_BEHAVIOR, --iodone=IO_DONE_BEHAVIOR
                        type of behavior when IO ends: IO_RUN_LATER,
                        IO_RUN_IMMEDIATE
  -c                    compute answers for me
  -p, --printstats      print statistics at end; only useful with -c flag
                        (otherwise stats are not printed)
....

* The most important option to understand is the PROCESS_LIST (as specified by
  the -l or --processlist flags) which specifies exactly what each running
  program (or 'process') will do.
* A process consists of instructions, and each instruction can just do one of
  two things:
** use the CPU
** issue an IO (and wait for it to complete)
* When a process uses the CPU (and does no IO at all), it should simply
  alternate between RUNNING on the CPU or being READY to run.
* For example, here is a simple run that just has one program being run, and
  that program only uses the CPU (it does no IO).

....
prompt> ./process-run.py -l 5:100 
Produce a trace of what would happen when you run these processes:
Process 0
  cpu
  cpu
  cpu
  cpu
  cpu

Important behaviors:
  System will switch when the current process is FINISHED or ISSUES AN IO
  After IOs, the process issuing the IO will run LATER (when it is its turn)

prompt> 
....

* Here, the process we specified is "5:100" which means it should consist of 5
  instructions, and the chances that each instruction is a CPU instruction are
  100%.

'''

* You can see what happens to the process by using the `-c` flag, which
  computes the answers for you:
+
....
prompt> ./process-run.py -l 5:100 -c
Time     PID: 0        CPU        IOs
  1     RUN:cpu          1
  2     RUN:cpu          1
  3     RUN:cpu          1
  4     RUN:cpu          1
  5     RUN:cpu          1
....

* This result is not too interesting: the process is simple in the RUN state
  and then finishes, using the CPU the whole time and thus keeping the CPU
  busy the entire run, and not doing any I/Os.

'''

* Let's make it slightly more complex by running two processes:
+
prompt> ./process-run.py -l 5:100,5:100
Produce a trace of what would happen when you run these processes:
Process 0
  cpu
  cpu
  cpu
  cpu
  cpu

Process 1
  cpu
  cpu
  cpu
  cpu
  cpu

Important behaviors:
  Scheduler will switch when the current process is FINISHED or ISSUES AN IO
  After IOs, the process issuing the IO will run LATER (when it is its turn)
....

* In this case, two different processes run, each again just using the CPU.
* What happens when the operating system runs them?
* Let's find out:
+
....
prompt> ./process-run.py -l 5:100,5:100 -c
Time     PID: 0     PID: 1        CPU        IOs
  1     RUN:cpu      READY          1
  2     RUN:cpu      READY          1
  3     RUN:cpu      READY          1
  4     RUN:cpu      READY          1
  5     RUN:cpu      READY          1
  6        DONE    RUN:cpu          1
  7        DONE    RUN:cpu          1
  8        DONE    RUN:cpu          1
  9        DONE    RUN:cpu          1
 10        DONE    RUN:cpu          1
....

* As you can see above, first the process with "process ID" (or "PID") 0 runs,
  while process 1 is READY to run but just waits until 0 is done.
* When 0 is finished, it moves to the DONE state, while 1 runs.
* When 1 finishes, the trace is done.

'''

* Let's look at one more example before getting to some questions.
* In this example, the process just issues I/O requests.
* We specify here that I/Os take 5 time units to complete with the flag -L.

....
prompt> ./process-run.py -l 3:0 -L 5
Produce a trace of what would happen when you run these processes:
Process 0
  io
  io_done
  io
  io_done
  io
  io_done

Important behaviors:
  System will switch when the current process is FINISHED or ISSUES AN IO
  After IOs, the process issuing the IO will run LATER (when it is its turn)
....

* What do you think the execution trace will look like?
* Let's find out:
+
....
prompt> ./process-run.py -l 3:0 -L 5 -c
Time    PID: 0       CPU       IOs
  1         RUN:io             1
  2        BLOCKED                           1
  3        BLOCKED                           1
  4        BLOCKED                           1
  5        BLOCKED                           1
  6        BLOCKED                           1
  7*   RUN:io_done             1
  8         RUN:io             1
  9        BLOCKED                           1
 10        BLOCKED                           1
 11        BLOCKED                           1
 12        BLOCKED                           1
 13        BLOCKED                           1
 14*   RUN:io_done             1
 15         RUN:io             1
 16        BLOCKED                           1
 17        BLOCKED                           1
 18        BLOCKED                           1
 19        BLOCKED                           1
 20        BLOCKED                           1
 21*   RUN:io_done             1
....

* As you can see, the program just issues three I/Os.
* When each I/O is issued, the process moves to a BLOCKED state, and while the
  device is busy servicing the I/O, the CPU is idle.

'''

* To handle the completion of the I/O, one more CPU action takes place.
* Note that a single instruction to handle I/O initiation and completion is
  not particularly realistic, but just used here for simplicity.

'''

* Let's print some stats (run the same command as above, but with the -p flag)
  to see some overall behaviors:
+
....
Stats: Total Time 21
Stats: CPU Busy 6 (28.57%)
Stats: IO Busy  15 (71.43%)
....

* As you can see, the trace took 21 clock ticks to run, but the CPU was busy
  less than 30% of the time.
* The I/O device, on the other hand, was quite busy.
* In general, we'd like to keep all the devices busy, as that is a better use
  of resources.

'''

* There are a few other important flags:
+
....
  -s SEED, --seed=SEED  the random seed  
    this gives you way to create a bunch of different jobs randomly

  -L IO_LENGTH, --iolength=IO_LENGTH
    this determines how long IOs take to complete (default is 5 ticks)

  -S PROCESS_SWITCH_BEHAVIOR, --switch=PROCESS_SWITCH_BEHAVIOR
                        when to switch between processes: SWITCH_ON_IO, SWITCH_ON_END
    this determines when we switch to another process:
    - SWITCH_ON_IO, the system will switch when a process issues an IO
    - SWITCH_ON_END, the system will only switch when the current process is done 

  -I IO_DONE_BEHAVIOR, --iodone=IO_DONE_BEHAVIOR
                        type of behavior when IO ends: IO_RUN_LATER, IO_RUN_IMMEDIATE
    this determines when a process runs after it issues an IO:
    - IO_RUN_IMMEDIATE: switch to this process right now
    - IO_RUN_LATER: switch to this process when it is natural to 
      (e.g., depending on process-switching behavior)
....

* Now go answer the questions at the back of the chapter to learn more,
  please.

=== Questions
:example-caption:

.{empty}
====
* Run `process-run.py` with the following flags: `-l 5:100,5:100`.
* What should the CPU utilization be (e.g., the percent of time the CPU is in
  use?)
* Why do you know this?
* Use the `-c` and `-p` flags to see if you were right.
====

....
Time        PID: 0        PID: 1           CPU           IOs
  1        RUN:cpu         READY             1          
  2        RUN:cpu         READY             1          
  3        RUN:cpu         READY             1          
  4        RUN:cpu         READY             1          
  5        RUN:cpu         READY             1          
  6           DONE       RUN:cpu             1          
  7           DONE       RUN:cpu             1          
  8           DONE       RUN:cpu             1          
  9           DONE       RUN:cpu             1          
 10           DONE       RUN:cpu             1          

Stats: Total Time 10
Stats: CPU Busy 10 (100.00%)
Stats: IO Busy  0 (0.00%)
....

.{empty}
====
* Now run with these flags: `./process-run.py -l 4:100,1:0`.
* These flags specify one process with 4 instructions (all to use the CPU),
  and one that simply issues an I/O and waits for it to be done.
* How long does it take to complete both processes?
* Use `-c` and `-p` to find out if you were right.
====

....
Time        PID: 0        PID: 1           CPU           IOs
  1        RUN:cpu         READY             1          
  2        RUN:cpu         READY             1          
  3        RUN:cpu         READY             1          
  4        RUN:cpu         READY             1          
  5           DONE        RUN:io             1          
  6           DONE       BLOCKED                           1
  7           DONE       BLOCKED                           1
  8           DONE       BLOCKED                           1
  9           DONE       BLOCKED                           1
 10           DONE       BLOCKED                           1
 11*          DONE   RUN:io_done             1          

Stats: Total Time 11
Stats: CPU Busy 6 (54.55%)
Stats: IO Busy  5 (45.45%)
....

.{empty}
====
* Switch the order of the processes: `-l 1:0,4:100`.
* What happens now?
* Does switching the order matter?
* Why?
* (As always, use `-c` and `-p` to see if you were right)
====

....
Time        PID: 0        PID: 1           CPU           IOs
  1         RUN:io         READY             1          
  2        BLOCKED       RUN:cpu             1             1
  3        BLOCKED       RUN:cpu             1             1
  4        BLOCKED       RUN:cpu             1             1
  5        BLOCKED       RUN:cpu             1             1
  6        BLOCKED          DONE                           1
  7*   RUN:io_done          DONE             1          

Stats: Total Time 7
Stats: CPU Busy 6 (85.71%)
Stats: IO Busy  5 (71.43%)
....

.{empty}
====
* We'll now explore some of the other flags.
* One important flag is `-S`, which determines how the system reacts when a
  process issues an I/O.
* With the flag set to SWITCH_ON_END, the system will NOT switch to another
  process while one is doing I/O, instead waiting until the process is
  completely finished.
* What happens when you run the following two processes (`-l 1:0,4:100 -c -S
  SWITCH_ON_END`), one doing I/O and the other doing CPU work?
====

....
Time        PID: 0        PID: 1           CPU           IOs
  1         RUN:io         READY             1          
  2        BLOCKED         READY                           1
  3        BLOCKED         READY                           1
  4        BLOCKED         READY                           1
  5        BLOCKED         READY                           1
  6        BLOCKED         READY                           1
  7*   RUN:io_done         READY             1          
  8           DONE       RUN:cpu             1          
  9           DONE       RUN:cpu             1          
 10           DONE       RUN:cpu             1          
 11           DONE       RUN:cpu             1          

Stats: Total Time 11
Stats: CPU Busy 6 (54.55%)
Stats: IO Busy  5 (45.45%)
....

.{empty}
====
* Now, run the same processes, but with the switching behavior set to switch
  to another process whenever one is WAITING for I/O (`-l 1:0,4:100 -c -S
  SWITCH_ON_IO`).
* What happens now?
* Use `-c` and `-p` to confirm that you are right.
====

....
Time        PID: 0        PID: 1           CPU           IOs
  1         RUN:io         READY             1          
  2        BLOCKED       RUN:cpu             1             1
  3        BLOCKED       RUN:cpu             1             1
  4        BLOCKED       RUN:cpu             1             1
  5        BLOCKED       RUN:cpu             1             1
  6        BLOCKED          DONE                           1
  7*   RUN:io_done          DONE             1          

Stats: Total Time 7
Stats: CPU Busy 6 (85.71%)
Stats: IO Busy  5 (71.43%)
....

.{empty}
====
* One other important behavior is what to do when an I/O completes.
* With `-I IO_RUN_LATER`, when an I/O completes, the process that issued it is
  not necessarily run right away; rather, whatever was running at the time
  keeps running.
* What happens when you run this combination of processes?
* (`./process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -c -p -I
  IO_RUN_LATER`)
* Are system resources being effectively utilized?
====

....
Time        PID: 0        PID: 1        PID: 2        PID: 3           CPU           IOs
  1         RUN:io         READY         READY         READY             1          
  2        BLOCKED       RUN:cpu         READY         READY             1             1
  3        BLOCKED       RUN:cpu         READY         READY             1             1
  4        BLOCKED       RUN:cpu         READY         READY             1             1
  5        BLOCKED       RUN:cpu         READY         READY             1             1
  6        BLOCKED       RUN:cpu         READY         READY             1             1
  7*         READY          DONE       RUN:cpu         READY             1          
  8          READY          DONE       RUN:cpu         READY             1          
  9          READY          DONE       RUN:cpu         READY             1          
 10          READY          DONE       RUN:cpu         READY             1          
 11          READY          DONE       RUN:cpu         READY             1          
 12          READY          DONE          DONE       RUN:cpu             1          
 13          READY          DONE          DONE       RUN:cpu             1          
 14          READY          DONE          DONE       RUN:cpu             1          
 15          READY          DONE          DONE       RUN:cpu             1          
 16          READY          DONE          DONE       RUN:cpu             1          
 17    RUN:io_done          DONE          DONE          DONE             1          
 18         RUN:io          DONE          DONE          DONE             1          
 19        BLOCKED          DONE          DONE          DONE                           1
 20        BLOCKED          DONE          DONE          DONE                           1
 21        BLOCKED          DONE          DONE          DONE                           1
 22        BLOCKED          DONE          DONE          DONE                           1
 23        BLOCKED          DONE          DONE          DONE                           1
 24*   RUN:io_done          DONE          DONE          DONE             1          
 25         RUN:io          DONE          DONE          DONE             1          
 26        BLOCKED          DONE          DONE          DONE                           1
 27        BLOCKED          DONE          DONE          DONE                           1
 28        BLOCKED          DONE          DONE          DONE                           1
 29        BLOCKED          DONE          DONE          DONE                           1
 30        BLOCKED          DONE          DONE          DONE                           1
 31*   RUN:io_done          DONE          DONE          DONE             1          

Stats: Total Time 31
Stats: CPU Busy 21 (67.74%)
Stats: IO Busy  15 (48.39%)
....

.{empty}
====
* Now run the same processes, but with `-I IO_RUN_IMMEDIATE` set, which
  immediately runs the process that issued the I/O.
* How does this behavior differ?
* Why might running a process that just completed an I/O again be a good idea?
====

....
Time        PID: 0        PID: 1        PID: 2        PID: 3           CPU           IOs
  1         RUN:io         READY         READY         READY             1          
  2        BLOCKED       RUN:cpu         READY         READY             1             1
  3        BLOCKED       RUN:cpu         READY         READY             1             1
  4        BLOCKED       RUN:cpu         READY         READY             1             1
  5        BLOCKED       RUN:cpu         READY         READY             1             1
  6        BLOCKED       RUN:cpu         READY         READY             1             1
  7*   RUN:io_done          DONE         READY         READY             1          
  8         RUN:io          DONE         READY         READY             1          
  9        BLOCKED          DONE       RUN:cpu         READY             1             1
 10        BLOCKED          DONE       RUN:cpu         READY             1             1
 11        BLOCKED          DONE       RUN:cpu         READY             1             1
 12        BLOCKED          DONE       RUN:cpu         READY             1             1
 13        BLOCKED          DONE       RUN:cpu         READY             1             1
 14*   RUN:io_done          DONE          DONE         READY             1          
 15         RUN:io          DONE          DONE         READY             1          
 16        BLOCKED          DONE          DONE       RUN:cpu             1             1
 17        BLOCKED          DONE          DONE       RUN:cpu             1             1
 18        BLOCKED          DONE          DONE       RUN:cpu             1             1
 19        BLOCKED          DONE          DONE       RUN:cpu             1             1
 20        BLOCKED          DONE          DONE       RUN:cpu             1             1
 21*   RUN:io_done          DONE          DONE          DONE             1          

Stats: Total Time 21
Stats: CPU Busy 21 (100.00%)
Stats: IO Busy  15 (71.43%)
....

.{empty}
====
* Now run with some randomly generated processes using flags `-s 1 -l
  3:50,3:50` or `-s 2 -l 3:50,3:50` or `-s 3 -l 3:50,3:50`.
* See if you can predict how the trace will turn out.
* What happens when you use the flag `-I IO_RUN_IMMEDIATE` versus that flag
  `-I IO_RUN_LATER`?
* What happens when you use the flag `-S SWITCH_ON_IO` versus `-S
  SWITCH_ON_END`?
====

....
$ ./process-run.py -s 1 -l 3:50,3:50 -cp
Time        PID: 0        PID: 1           CPU           IOs
  1        RUN:cpu         READY             1          
  2         RUN:io         READY             1          
  3        BLOCKED       RUN:cpu             1             1
  4        BLOCKED       RUN:cpu             1             1
  5        BLOCKED       RUN:cpu             1             1
  6        BLOCKED          DONE                           1
  7        BLOCKED          DONE                           1
  8*   RUN:io_done          DONE             1          
  9         RUN:io          DONE             1          
 10        BLOCKED          DONE                           1
 11        BLOCKED          DONE                           1
 12        BLOCKED          DONE                           1
 13        BLOCKED          DONE                           1
 14        BLOCKED          DONE                           1
 15*   RUN:io_done          DONE             1          

Stats: Total Time 15
Stats: CPU Busy 8 (53.33%)
Stats: IO Busy  10 (66.67%)
....

....
$ ./process-run.py -s 2 -l 3:50,3:50 -cp
Time        PID: 0        PID: 1           CPU           IOs
  1         RUN:io         READY             1          
  2        BLOCKED       RUN:cpu             1             1
  3        BLOCKED        RUN:io             1             1
  4        BLOCKED       BLOCKED                           2
  5        BLOCKED       BLOCKED                           2
  6        BLOCKED       BLOCKED                           2
  7*   RUN:io_done       BLOCKED             1             1
  8         RUN:io       BLOCKED             1             1
  9*       BLOCKED   RUN:io_done             1             1
 10        BLOCKED        RUN:io             1             1
 11        BLOCKED       BLOCKED                           2
 12        BLOCKED       BLOCKED                           2
 13        BLOCKED       BLOCKED                           2
 14*   RUN:io_done       BLOCKED             1             1
 15        RUN:cpu       BLOCKED             1             1
 16*          DONE   RUN:io_done             1          

Stats: Total Time 16
Stats: CPU Busy 10 (62.50%)
Stats: IO Busy  14 (87.50%)
....

....
$ ./process-run.py -s 3 -l 3:50,3:50 -cp
Time        PID: 0        PID: 1           CPU           IOs
  1        RUN:cpu         READY             1          
  2         RUN:io         READY             1          
  3        BLOCKED        RUN:io             1             1
  4        BLOCKED       BLOCKED                           2
  5        BLOCKED       BLOCKED                           2
  6        BLOCKED       BLOCKED                           2
  7        BLOCKED       BLOCKED                           2
  8*   RUN:io_done       BLOCKED             1             1
  9*       RUN:cpu         READY             1          
 10           DONE   RUN:io_done             1          
 11           DONE        RUN:io             1          
 12           DONE       BLOCKED                           1
 13           DONE       BLOCKED                           1
 14           DONE       BLOCKED                           1
 15           DONE       BLOCKED                           1
 16           DONE       BLOCKED                           1
 17*          DONE   RUN:io_done             1          
 18           DONE       RUN:cpu             1          

Stats: Total Time 18
Stats: CPU Busy 9 (50.00%)
Stats: IO Busy  11 (61.11%)
....

....
$ ./process-run.py -s 1 -l 3:50,3:50 -I IO_RUN_IMMEDIATE -cp
Time        PID: 0        PID: 1           CPU           IOs
  1        RUN:cpu         READY             1          
  2         RUN:io         READY             1          
  3        BLOCKED       RUN:cpu             1             1
  4        BLOCKED       RUN:cpu             1             1
  5        BLOCKED       RUN:cpu             1             1
  6        BLOCKED          DONE                           1
  7        BLOCKED          DONE                           1
  8*   RUN:io_done          DONE             1          
  9         RUN:io          DONE             1          
 10        BLOCKED          DONE                           1
 11        BLOCKED          DONE                           1
 12        BLOCKED          DONE                           1
 13        BLOCKED          DONE                           1
 14        BLOCKED          DONE                           1
 15*   RUN:io_done          DONE             1          

Stats: Total Time 15
Stats: CPU Busy 8 (53.33%)
Stats: IO Busy  10 (66.67%)
....

....
$ ./process-run.py -s 1 -l 3:50,3:50 -I IO_RUN_LATER -cp
Time        PID: 0        PID: 1           CPU           IOs
  1        RUN:cpu         READY             1          
  2         RUN:io         READY             1          
  3        BLOCKED       RUN:cpu             1             1
  4        BLOCKED       RUN:cpu             1             1
  5        BLOCKED       RUN:cpu             1             1
  6        BLOCKED          DONE                           1
  7        BLOCKED          DONE                           1
  8*   RUN:io_done          DONE             1          
  9         RUN:io          DONE             1          
 10        BLOCKED          DONE                           1
 11        BLOCKED          DONE                           1
 12        BLOCKED          DONE                           1
 13        BLOCKED          DONE                           1
 14        BLOCKED          DONE                           1
 15*   RUN:io_done          DONE             1          

Stats: Total Time 15
Stats: CPU Busy 8 (53.33%)
Stats: IO Busy  10 (66.67%)
....

....
$ ./process-run.py -s 1 -l 3:50,3:50 -I IO_RUN_IMMEDIATE -S SWITCH_ON_IO -cp
Time        PID: 0        PID: 1           CPU           IOs
  1        RUN:cpu         READY             1          
  2         RUN:io         READY             1          
  3        BLOCKED       RUN:cpu             1             1
  4        BLOCKED       RUN:cpu             1             1
  5        BLOCKED       RUN:cpu             1             1
  6        BLOCKED          DONE                           1
  7        BLOCKED          DONE                           1
  8*   RUN:io_done          DONE             1          
  9         RUN:io          DONE             1          
 10        BLOCKED          DONE                           1
 11        BLOCKED          DONE                           1
 12        BLOCKED          DONE                           1
 13        BLOCKED          DONE                           1
 14        BLOCKED          DONE                           1
 15*   RUN:io_done          DONE             1          

Stats: Total Time 15
Stats: CPU Busy 8 (53.33%)
Stats: IO Busy  10 (66.67%)
....

....
$ ./process-run.py -s 1 -l 3:50,3:50 -I IO_RUN_IMMEDIATE -S SWITCH_ON_END -cp
Time        PID: 0        PID: 1           CPU           IOs
  1        RUN:cpu         READY             1          
  2         RUN:io         READY             1          
  3        BLOCKED         READY                           1
  4        BLOCKED         READY                           1
  5        BLOCKED         READY                           1
  6        BLOCKED         READY                           1
  7        BLOCKED         READY                           1
  8*   RUN:io_done         READY             1          
  9         RUN:io         READY             1          
 10        BLOCKED         READY                           1
 11        BLOCKED         READY                           1
 12        BLOCKED         READY                           1
 13        BLOCKED         READY                           1
 14        BLOCKED         READY                           1
 15*   RUN:io_done         READY             1          
 16           DONE       RUN:cpu             1          
 17           DONE       RUN:cpu             1          
 18           DONE       RUN:cpu             1          

Stats: Total Time 18
Stats: CPU Busy 8 (44.44%)
Stats: IO Busy  10 (55.56%)
....

....
$ ./process-run.py -s 1 -l 3:50,3:50 -I IO_RUN_LATER -S SWITCH_ON_IO -cp
Time        PID: 0        PID: 1           CPU           IOs
  1        RUN:cpu         READY             1          
  2         RUN:io         READY             1          
  3        BLOCKED       RUN:cpu             1             1
  4        BLOCKED       RUN:cpu             1             1
  5        BLOCKED       RUN:cpu             1             1
  6        BLOCKED          DONE                           1
  7        BLOCKED          DONE                           1
  8*   RUN:io_done          DONE             1          
  9         RUN:io          DONE             1          
 10        BLOCKED          DONE                           1
 11        BLOCKED          DONE                           1
 12        BLOCKED          DONE                           1
 13        BLOCKED          DONE                           1
 14        BLOCKED          DONE                           1
 15*   RUN:io_done          DONE             1          

Stats: Total Time 15
Stats: CPU Busy 8 (53.33%)
Stats: IO Busy  10 (66.67%)
....

....
$ ./process-run.py -s 1 -l 3:50,3:50 -I IO_RUN_LATER -S SWITCH_ON_END -cp
Time        PID: 0        PID: 1           CPU           IOs
  1        RUN:cpu         READY             1          
  2         RUN:io         READY             1          
  3        BLOCKED         READY                           1
  4        BLOCKED         READY                           1
  5        BLOCKED         READY                           1
  6        BLOCKED         READY                           1
  7        BLOCKED         READY                           1
  8*   RUN:io_done         READY             1          
  9         RUN:io         READY             1          
 10        BLOCKED         READY                           1
 11        BLOCKED         READY                           1
 12        BLOCKED         READY                           1
 13        BLOCKED         READY                           1
 14        BLOCKED         READY                           1
 15*   RUN:io_done         READY             1          
 16           DONE       RUN:cpu             1          
 17           DONE       RUN:cpu             1          
 18           DONE       RUN:cpu             1          

Stats: Total Time 18
Stats: CPU Busy 8 (44.44%)
Stats: IO Busy  10 (55.56%)
....
