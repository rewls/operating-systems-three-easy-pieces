= 28 Locks
:figure-caption: Figure 28.
:source-highlighter: rouge
:tabsize: 8
:toc: left

* From the introduction to concurrency, we saw one of the fundamental problems
  in concurrent programming: we would like to execute a series of instructions
  atomically, but due to the presence of interrupts on a single processor (or
  multiple threads executing on multiple processors concurrently), we
  couldn't.
* In this chapter, we thus attack this problem directly, with the introduction
  of something referred to as a *lock*.
* Programmers annotate source code with locks, putting them around critical
  sections, and thus ensure that any such critical section executes as if it
  were a single atomic instruction.

== 28.1 Locks: The Basic Idea

* As an example, assume our critical section looks like this, the canonical
  update of a shared variable:

[source,c]
balance = balance + 1;

'''

* Of course, other critical sections are possible, such as adding an element
  to a linked list or other more complex updates to shared structures, but
  we'll just keep to this simple example for now.
* To use a lock, we add some code around the critical section like this:

[source,c]
lock_t mutex; // some globally-allocated lock 'mutex'
...
lock(&mutex);
balance = balance + 1;
unlock(&mutex);

'''

* A lock is just a variable, and thus to use one, you must declare a *lock
  variable* of some kind (such as `mutex` above).
* This lock variable (or just "lock" for short) holds the state of the lock at
  any instant in time.
* It is either *available* (or *unlocked* or *free*) and thus no thread holds
  the lock, or *acquired* (or *locked* or *held*), and thus exactly one thread
  holds the lock and presumably is in a critical section.
* We could store other information in the data type as well, such as which
  thread holds the lock, or a queue for ordering lock acquisition, but
  information like that is hidden from the user of the lock.

'''

* The semantics of the `lock()` and `unlock()` routines are simple.
* Calling the routine `lock()` tries to acquire the lock; if no other thread
  holds the lock (i.e., it is free), the thread will acquire the lock and
  enter the critical section; this thread is sometimes said to be the *owner*
  of the lock.
* If another thread then calls `lock()` on that same lock variable (`mutex` in
  this example), it will not return while the lock is held by another thread;
  in this way, other threads are prevented from entering the critical section
  while the first thread that holds the lock is in there.

'''

* Once the owner of the lock calls `unlock()`, the lock is now available
  (free) again.
* If no other threads are waiting for the lock (i.e., no other thread has
  called `lock()` and is stuck therein), the state of the lock is simply changed
  to free.
* If there are waiting threads (stuck in `lock()`), one of them will
  (eventually) notice (or be informed of) this change of the lock's state,
  acquire the lock, and enter the critical section.

'''

* Locks provide some minimal amount of control over scheduling to programmers.
* In general, we view threads as entities created by the programmer but
  scheduled by the OS, in any fashion that the OS chooses.
* Locks yield some of that control back to the programmer; by putting a lock
  around a section of code, the programmer can guarantee that no more than a
  single thread can ever be active within that code.
* Thus locks help transform the chaos that is traditional OS scheduling into a
  more controlled activity.

== 28.2 Pthread Locks

* The name that the POSIX library uses for a lock is a *mutex*, as it is used
  to provide mutual exclusion between threads, i.e., if one thread is in the
  critical section, it excludes the others from entering until it has
  completed the section.
* Thus, when you see the following POSIX threads code, you should understand
  that it is doing the same thing as above (we again use our wrappers that
  check for errors upon lock and unlock):

[,c]
----
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;

Pthread_mutex_lock(&lock); // wrapper; exits on failure
balance = balance + 1;
Pthread_mutex_unlock(&lock);
----

* You might also notice here that the POSIX version passes a variable to lock
  and unlock, as we may be using _different_ locks to protect different
  variables.
* Doing so can increase concurrency: instead of one big lock that is used any
  time any critical section is accessed (a *coarse-grained* locking strategy),
  one will often protect different data and data structures with different
  locks, thus allowing more threads to be in locked code at once (a more
  *fine-grained* approach).

== 28.3 Building A Lock

* By now, you should have some understanding of how a lock works, from the
  perspective of a programmer.
* But how should we build a lock?
* What hardware support is needed?
* What OS support?
* It is this set of questions we address in the rest of this chapter.

.The crux: How to build a lock
****
* How can we build an efficient lock?
* Efficient locks provide mutual exclusion at low cost, and also might attain
  a few other properties we discuss below.
* What hardware support is needed?
* What OS support?
****

* To build a working lock, we will need some help from our old friend, the
  hardware, as well as our good pal, the OS.
* Over the years, a number of different hardware primitives have been added to
  the instruction sets of various computer architectures; while we won't study
  how these instructions are implemented (that, after all, is the topic of a
  computer architecture class), we will study how to use them in order to
  build a mutual exclusion primitive like a lock.
* We will also study how the OS gets involved to complete the picture and
  enable us to build a sophisticated locking library.

== 28.4 Evaluating Locks

* Before building any locks, we should first understand what our goals are,
  and thus we ask how to evaluate the efficacy of a particular lock
  implementation.
* To evaluate whether a lock works (and works well), we should establish some
  basic criteria.
* The first is whether the lock does its basic task, which is to provide
  *mutual exclusion*.
* Basically, does the lock work, preventing multiple threads from entering a
  critical section?

'''

* The second is *fairness*.
* Does each thread contending for the lock get a fair shot at acquiring it
  once it is free?
* Another way to look at this is by examining the more extreme case: does any
  thread contending for the lock *starve* while doing so, thus never obtaining
  it?

'''

* The final criterion is *performance*, specifically the time overheads added
  by using the lock.
* There are a few different cases that are worth considering here.
* One is the case of no contention; when a single thread is running and grabs
  and releases the lock, what is the overhead of doing so?
* Another is the case where multiple threads are contending for the lock on a
  single CPU; in this case, are there performance concerns?
* Finally, how does the lock perform when there are multiple CPUs involved,
  and threads on each contending for the lock?
* By comparing these different scenarios, we can better understand the
  performance impact of using various locking techniques, as described below.

== 28.5 Controlling Interrupts

* One of the earliest solutions used to provide mutual exclusion was to
  disable interrupts for critical sections; this solution was invented for
  single-processor systems.
* The code would look like this:

[source,c]
void lock() {
	DisableInterrupts();
}
void unlock() {
	EnableInterrupts();
}

* Assume we are running on such a single-processor system.
* By turning off interrupts (using some kind of special hardware instruction)
  before entering a critical section, we ensure that the code inside the
  critical section will not be interrupted, and thus will execute as if it
  were atomic.
* When we are finished, we re-enable interrupts (again, via a hardware
  instruction) and thus the program proceeds as usual.

'''

* The main positive of this approach is its simplicity.
* You certainly don't have to scratch your head too hard to figure out why
  this works.
* Without interruption, a thread can be sure that the code it executes will
  execute and that no other thread will interfere with it.

'''

* The negatives, unfortunately, are many.
* First, this approach requires us to allow any calling thread to perform a
  privileged operation (turning interrupts on and off), and thus trust that
  this facility is not abused.
* As you already know, any time we are required to trust an arbitrary program,
  we are probably in trouble.
* Here, the trouble manifests in numerous ways: a greedy program could call
  `lock()` at the beginning of its execution and thus monopolize the
  processor; worse, an errant or malicious program could call `lock()` and go
  into an endless loop.
* In this latter case, the OS never regains control of the system, and there
  is only one recourse: restart the system.
* Using interrupt disabling as a general-purpose synchronization solution
  requires too much trust in applications.

'''

* Second, the approach does not work on multiprocessors.
* If multiple threads are running on different CPUs, and each try to enter the
  same critical section, it does not matter whether interrupts are disabled;
  threads will be able to run on other processors, and thus could enter the
  critical section.
* As multiprocessors are now commonplace, our general solution will have to do
  better than this.

'''

* Third, turning off interrupts for extended periods of time can lead to
  interrupts becoming lost, which can lead to serious systems problems.
* Imagine, for example, if the CPU missed the fact that a disk device has
  finished a read request.
* How will the OS know to wake the process waiting for said read?

'''

* For these reasons, turning off interrupts is only used in limited contexts
  as a mutual-exclusion primitive.
* For example, in some cases an operating system itself will use interrupt
  masking to guarantee atomicity when accessing its own data structures, or at
  least to prevent certain messy interrupt handling situations from arising.
* This usage makes sense, as the trust issue disappears inside the OS, which
  always trusts itself to perform privileged operations anyhow.

== 28.6 A Failed Attempt: Just Using Loads/Stores

* To move beyond interrupt-based techniques, we will have to rely on CPU
  hardware and the instructions it provides us to build a proper lock.
* Let's first try to build a simple lock by using a single flag variable.
* In this failed attempt, we'll see some of the basic ideas needed to build a
  lock, and (hopefully) see why just using a single variable and accessing it
  via normal loads and stores is insufficient.

'''

* In this first attempt (Figure 28.1), the idea is quite simple: use a simple
  variable (`flag`) to indicate whether some thread has possession of a lock.
* The first thread that enters the critical section will call `lock()`, which
  *tests* whether the flag is equal to 1 (in this case, it is not), and then
  *sets* the flag to 1 to indicate that the thread now *holds* the lock.
* When finished with the critical section, the thread calls `unlock()` and
  clears the flag, thus indicating that the lock is no longer held.

:figure-number: {counter:figure-number}
.{figure-caption} {figure-number}. First Attempt: A Simple Flag
[,c]
----
typedef struct __lock_t { int flag; } lock_t;

void init(lock_t *mutex) {
	// 0 -> lock is available, 1 -> held
	mutex->flag = 0;
}

void lock(lock_t *mutex) {
	while (mutex->flag == 1) // TEST the flag
		; // spin-wait (do nothing)
	mutex->flag = 1; // now SET it!
}

void unlock(lock_t *mutex) {
	mutex->flag = 0;
}
----

* If another thread happens to call `lock()` while that first thread is in the
  critical section, it will simply *spin-wait* in the while loop for that
  thread to call `unlock()` and clear the flag.
* Once that first thread does so, the waiting thread will fall out of the
  while loop, set the flag to 1 for itself, and proceed into the critical
  section.

'''

* Unfortunately, the code has two problems: one of correctness, and another of
  performance.
* The correctness problem is simple to see once you get used to thinking about
  concurrent programming.
* Imagine the code interleaving in Figure 28.2; assume `flag=0` to begin.

:figure-number: {counter:figure-number}
.{figure-caption} {figure-number}. Trace: No Mutual Exclusion
[%autowidth]
|===
|Thread 1				|Thread 2

|call `lock()`
|while (flag == 1)
|*interrupt: switch to Thread 2*
|					|call `lock()`
|					|while (flag == 1)
|					|flag = 1;
|					|*interrupt: switch to Thread 1*
|flag = 1; // set flag to 1 (too!)
|===

* As you can see from this interleaving, with timely (untimely?) interrupts,
  we can easily produce a case where both threads set the flag to 1 and both
  threads are thus able to enter the critical section.
* This behavior is what professionals call "bad" -- we have obviously failed
  to provide the most basic requirement: providing mutual exclusion.

'''

* The performance problem, which we will address more later on, is the fact
  that the way a thread waits to acquire a lock that is already held: it
  endlessly checks the value of flag, a technique known as *spin-waiting*.
* Spin-waiting wastes time waiting for another thread to release a lock.
* The waste is exceptionally high on a uniprocessor, where the thread that the
  waiter is waiting for cannot even run (at least, until a context switch
  occurs)!
* Thus, as we move forward and develop more sophisticated solutions, we should
  also consider ways to avoid this kind of waste.

.Aside: Dekker's and Peterson's algorithms
****
* In the 1960's, Dijkstra posed the concurrency problem to his friends, and
  one of them, a mathematician named Theodorus Jozef Dekker, came up with a
  solution [D68].
* Unlike the solutions we discuss here, which use special hardware
  instructions and even OS support, *Dekker's algorithm* uses just loads and
  stores (assuming they are atomic with respect to each other, which was true
  on early hardware).

'''

* Dekker's approach was later refined by Peterson [P81].
* Once again, just loads and stores are used, and the idea is to ensure that
  two threads never enter a critical section at the same time.
* Here is *Peterson's algorithm* (for two threads); see if you can understand
  the code.
* What are the `flag` and `turn` variables used for?

[,c]
----
int flag[2];
int turn;

void init() {
    // indicate you intend to hold the lock w/ 'flag'
    flag[0] = flag[1] = 0;
    // whose turn is it? (thread 0 or 1)
    turn = 0;
}

void lock() {
    // 'self' is the thread ID of caller
    flag[self] = 1;
    // make it other thread's turn
    turn = 1 - self;
    while ((flag[1-self] == 1) && (turn == 1 - self))
	; // spin-wait while it’s not your turn
}
void unlock() {
    // simply undo your intent
    flag[self] = 0;
}
----

* For some reason, developing locks that work without special hardware support
  became all the rage for a while, giving theory-types a lot of problems to
  work on.
* Of course, this line of work became quite useless when people realized it is
  much easier to assume a little hardware support (and indeed that support had
  been around from the earliest days of multiprocessing).
* Further, algorithms like the ones above don't work on modern hardware (due
  to relaxed memory consistency models), thus making them even less useful
  than they were before.
* Yet more research relegated to the dustbin of history...
****
