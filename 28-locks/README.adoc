= 28 Locks
:source-highlighter: rouge
:tabsize: 8
:toc: left

* From the introduction to concurrency, we saw one of the fundamental problems
  in concurrent programming: we would like to execute a series of instructions
  atomically, but due to the presence of interrupts on a single processor (or
  multiple threads executing on multiple processors concurrently), we
  couldn't.
* In this chapter, we thus attack this problem directly, with the introduction
  of something referred to as a *lock*.
* Programmers annotate source code with locks, putting them around critical
  sections, and thus ensure that any such critical section executes as if it
  were a single atomic instruction.

== 28.1 Locks: The Basic Idea

* As an example, assume our critical section looks like this, the canonical
  update of a shared variable:

[source,c]
balance = balance + 1;

'''

* Of course, other critical sections are possible, such as adding an element
  to a linked list or other more complex updates to shared structures, but
  we'll just keep to this simple example for now.
* To use a lock, we add some code around the critical section like this:

[source,c]
lock_t mutex; // some globally-allocated lock 'mutex'
...
lock(&mutex);
balance = balance + 1;
unlock(&mutex);

'''

* A lock is just a variable, and thus to use one, you must declare a *lock
  variable* of some kind (such as `mutex` above).
* This lock variable (or just "lock" for short) holds the state of the lock at
  any instant in time.
* It is either *available* (or *unlocked* or *free*) and thus no thread holds
  the lock, or *acquired* (or *locked* or *held*), and thus exactly one thread
  holds the lock and presumably is in a critical section.
* We could store other information in the data type as well, such as which
  thread holds the lock, or a queue for ordering lock acquisition, but
  information like that is hidden from the user of the lock.

'''

* The semantics of the `lock()` and `unlock()` routines are simple.
* Calling the routine `lock()` tries to acquire the lock; if no other thread
  holds the lock (i.e., it is free), the thread will acquire the lock and
  enter the critical section; this thread is sometimes said to be the *owner*
  of the lock.
* If another thread then calls `lock()` on that same lock variable (`mutex` in
  this example), it will not return while the lock is held by another thread;
  in this way, other threads are prevented from entering the critical section
  while the first thread that holds the lock is in there.

'''

* Once the owner of the lock calls `unlock()`, the lock is now available
  (free) again.
* If no other threads are waiting for the lock (i.e., no other thread has
  called `lock()` and is stuck therein), the state of the lock is simply changed
  to free.
* If there are waiting threads (stuck in `lock()`), one of them will
  (eventually) notice (or be informed of) this change of the lock's state,
  acquire the lock, and enter the critical section.

'''

* Locks provide some minimal amount of control over scheduling to programmers.
* In general, we view threads as entities created by the programmer but
  scheduled by the OS, in any fashion that the OS chooses.
* Locks yield some of that control back to the programmer; by putting a lock
  around a section of code, the programmer can guarantee that no more than a
  single thread can ever be active within that code.
* Thus locks help transform the chaos that is traditional OS scheduling into a
  more controlled activity.

== 28.2 Pthread Locks

* The name that the POSIX library uses for a lock is a *mutex*, as it is used
  to provide mutual exclusion between threads, i.e., if one thread is in the
  critical section, it excludes the others from entering until it has
  completed the section.
* Thus, when you see the following POSIX threads code, you should understand
  that it is doing the same thing as above (we again use our wrappers that
  check for errors upon lock and unlock):

[,c]
----
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;

Pthread_mutex_lock(&lock); // wrapper; exits on failure
balance = balance + 1;
Pthread_mutex_unlock(&lock);
----

* You might also notice here that the POSIX version passes a variable to lock
  and unlock, as we may be using _different_ locks to protect different
  variables.
* Doing so can increase concurrency: instead of one big lock that is used any
  time any critical section is accessed (a *coarse-grained* locking strategy),
  one will often protect different data and data structures with different
  locks, thus allowing more threads to be in locked code at once (a more
  *fine-grained* approach).

== 28.3 Building A Lock

* By now, you should have some understanding of how a lock works, from the
  perspective of a programmer.
* But how should we build a lock?
* What hardware support is needed?
* What OS support?
* It is this set of questions we address in the rest of this chapter.

.The crux: How to build a lock
****
* How can we build an efficient lock?
* Efficient locks provide mutual exclusion at low cost, and also might attain
  a few other properties we discuss below.
* What hardware support is needed?
* What OS support?
****

* To build a working lock, we will need some help from our old friend, the
  hardware, as well as our good pal, the OS.
* Over the years, a number of different hardware primitives have been added to
  the instruction sets of various computer architectures; while we won't study
  how these instructions are implemented (that, after all, is the topic of a
  computer architecture class), we will study how to use them in order to
  build a mutual exclusion primitive like a lock.
* We will also study how the OS gets involved to complete the picture and
  enable us to build a sophisticated locking library.

== 28.4 Evaluating Locks

* Before building any locks, we should first understand what our goals are,
  and thus we ask how to evaluate the efficacy of a particular lock
  implementation.
* To evaluate whether a lock works (and works well), we should establish some
  basic criteria.
* The first is whether the lock does its basic task, which is to provide
  *mutual exclusion*.
* Basically, does the lock work, preventing multiple threads from entering a
  critical section?

'''

* The second is *fairness*.
* Does each thread contending for the lock get a fair shot at acquiring it
  once it is free?
* Another way to look at this is by examining the more extreme case: does any
  thread contending for the lock *starve* while doing so, thus never obtaining
  it?

'''

* The final criterion is *performance*, specifically the time overheads added
  by using the lock.
* There are a few different cases that are worth considering here.
* One is the case of no contention; when a single thread is running and grabs
  and releases the lock, what is the overhead of doing so?
* Another is the case where multiple threads are contending for the lock on a
  single CPU; in this case, are there performance concerns?
* Finally, how does the lock perform when there are multiple CPUs involved,
  and threads on each contending for the lock?
* By comparing these different scenarios, we can better understand the
  performance impact of using various locking techniques, as described below.

== 28.5 Controlling Interrupts

* One of the earliest solutions used to provide mutual exclusion was to
  disable interrupts for critical sections; this solution was invented for
  single-processor systems.
* The code would look like this:

[source,c]
void lock() {
	DisableInterrupts();
}
void unlock() {
	EnableInterrupts();
}

* Assume we are running on such a single-processor system.
* By turning off interrupts (using some kind of special hardware instruction)
  before entering a critical section, we ensure that the code inside the
  critical section will not be interrupted, and thus will execute as if it
  were atomic.
* When we are finished, we re-enable interrupts (again, via a hardware
  instruction) and thus the program proceeds as usual.

'''

* The main positive of this approach is its simplicity.
* You certainly don't have to scratch your head too hard to figure out why
  this works.
* Without interruption, a thread can be sure that the code it executes will
  execute and that no other thread will interfere with it.

'''

* The negatives, unfortunately, are many.
* First, this approach requires us to allow any calling thread to perform a
  privileged operation (turning interrupts on and off), and thus trust that
  this facility is not abused.
* As you already know, any time we are required to trust an arbitrary program,
  we are probably in trouble.
* Here, the trouble manifests in numerous ways: a greedy program could call
  `lock()` at the beginning of its execution and thus monopolize the
  processor; worse, an errant or malicious program could call `lock()` and go
  into an endless loop.
* In this latter case, the OS never regains control of the system, and there
  is only one recourse: restart the system.
* Using interrupt disabling as a general-purpose synchronization solution
  requires too much trust in applications.

'''

* Second, the approach does not work on multiprocessors.
* If multiple threads are running on different CPUs, and each try to enter the
  same critical section, it does not matter whether interrupts are disabled;
  threads will be able to run on other processors, and thus could enter the
  critical section.
* As multiprocessors are now commonplace, our general solution will have to do
  better than this.

'''

* Third, turning off interrupts for extended periods of time can lead to
  interrupts becoming lost, which can lead to serious systems problems.
* Imagine, for example, if the CPU missed the fact that a disk device has
  finished a read request.
* How will the OS know to wake the process waiting for said read?

'''

* For these reasons, turning off interrupts is only used in limited contexts
  as a mutual-exclusion primitive.
* For example, in some cases an operating system itself will use interrupt
  masking to guarantee atomicity when accessing its own data structures, or at
  least to prevent certain messy interrupt handling situations from arising.
* This usage makes sense, as the trust issue disappears inside the OS, which
  always trusts itself to perform privileged operations anyhow.
