= 36 I/O Devices
:figure-caption: Figure 36.
:imagesdir: images
:source-highlighter: rouge
:tabsize: 8
:toc: left

* Before delving into the main content of this part of the book (on
  persistence), we first introduce the concept of an *input/output (I/O)
  device* and show how the operating system might interact with such an
  entity.
* I/O is quite critical to computer systems, of course; imagine a program
  without any input (it produces the same result each time); now imagine a
  program with no output (what was the purpose of it running?).
* Clearly, for computer systems to be interesting, both input and output are
  required.
* And thus, our general problem:

.Crux: How to integrate I/O into systems
****
* How should I/O be integrated into systems?
* What are the general mechanisms?
* How can we make them efficient?
****

== 36.1 System Architecture

* To begin our discussion, let's look at a "classical" diagram of a typical
  system (Figure 36.1, page 2).
* The picture shows a single CPU attached to the main memory of the system via
  some kind of *memory bus* or interconnect.
* Some devices are connected to the system via a general *I/O bus*, which in
  many modern systems would be *PCI* (or one of its many derivatives);
  graphics and some other higher-performance I/O devices might be found here.
* Finally, even lower down are one or more of what we call a *peripheral bus*,
  such as *SCSI*, *SATA*, or *USB*.
* These connect slow devices to the system, including *disks*, *mice*, and
  *keyboards*.

.Prototypical System Architecture
image::figure-36-01.png[]

* One question you might ask is: why do we need a hierarchical structure like
  this?
* Put simply: physics, and cost.
* The faster a bus is, the shorter it must be; thus, a high-performance memory
  bus does not have much room to plug devices and such into it.
* In addition, engineering a bus for high performance is quite costly.
* Thus, system designers have adopted this hierarchical approach, where
  components that demand high performance (such as the graphics card) are
  nearer the CPU.
* Lower performance components are further away.
* The benefits of placing disks and other slow devices on a peripheral bus are
  manifold; in particular, you can place a large number of devices on it.

'''

* Of course, modern systems increasingly use specialized chipsets and faster
  point-to-point interconnects to improve performance.
* Figure 36.2 (page 3) shows an approximate diagram of Intel's Z270 Chipset
  [H17].
* Along the top, the CPU connects most closely to the memory system, but also
  has a high-performance connection to the graphics card (and thus, the
  display) to enable gaming (oh, the horror!) and other graphics-intensive
  applications.

.Modern System Architecture
image::figure-36-02.png[]

* The CPU connects to an I/O chip via Intel's proprietary *DMI* (*Direct Media
  Interface*), and the rest of the devices connect to this chip via a number
  of different interconnects.
* On the right, one or more hard drives connect to the system via the *eSATA*
  interface; *ATA* (the *AT Attachment*, in reference to providing connection
  to the IBM PC AT), then *SATA* (for *Serial ATA*), and now *eSATA* (for
  *external SATA*) represent an evolution of storage interfaces over the past
  decades, with each step forward increasing performance to keep pace with
  modern storage devices.

'''

* Below the I/O chip are a number of *USB* (*Universal Serial Bus*)
  connections, which in this depiction enable a keyboard and mouse to be
  attached to the computer.
* On many modern systems, USB is used for low performance devices such as
  these.

'''

* Finally, on the left, other higher performance devices can be connected to
  the system via *PCIe* (*Peripheral Component Interconnect Express*).
* In this diagram, a network interface is attached to the system here; higher
  performance storage devices (such as *NVMe* persistent storage devices) are
  often connected here.

== 36.2 A Canonical Device

* Let us now look at a canonical device (not a real one), and use this device
  to drive our understanding of some of the machinery required to make device
  interaction efficient.
* From Figure 36.3 (page 4), we can see that a device has two important
  components.
* The first is the hardware *interface* it presents to the rest of the system.
* Just like a piece of software, hardware must also present some kind of
  interface that allows the system software to control its operation.
* Thus, all devices have some specified interface and protocol for typical
  interaction.

.A Canonical Device
image::figure-36-03.png[]

* The second part of any device is its *internal structure*.
* This part of the device is implementation specific and is responsible for
  implementing the abstraction the device presents to the system.
* Very simple devices will have one or a few hardware chips to implement their
  functionality; more complex devices will include a simple CPU, some general
  purpose memory, and other device-specific chips to get their job done.
* For example, modern RAID controllers might consist of hundreds of thousands
  of lines of *firmware* (i.e., software within a hardware device) to
  implement its functionality.

== 36.3 The Canonical Protocol

* In the picture above, the (simplified) device interface is comprised of
  three registers: a status register, which can be read to see the current
  *status* of the device; a *command* register, to tell the device to perform
  a certain task; and a *data register to pass data to the device, or get data
  from the device.
* By reading and writing these registers, the operating system can control
  device behavior.

'''

* Let us now describe a typical interaction that the OS might have with the
  device in order to get the device to do something on its behalf.
* The protocol is as follows:

[source,c]
While (STATUS == BUSY)
	; // wait until device is not busy
Write data to DATA register
Write command to COMMAND register
(starts the device and executes the command)
While (STATUS == BUSY)
	; // wait until device is done with your request

* The protocol has four steps.
* In the first, the OS waits until the device is ready to receive a command by
  repeatedly reading the status register; we call this *polling* the device
  (basically, just asking it what is going on).
* Second, the OS sends some data down to the data register; one can imagine
  that if this were a disk, for example, that multiple writes would need to
  take place to transfer a disk block (say 4KB) to the device.
* When the main CPU is involved with the data movement (as in this example
  protocol), we refer to it as *programmed I/O (PIO)*.
* Third, the OS writes a command to the command register; doing so implicitly
  lets the device know that both the data is present and that it should begin
  working on the command.
* Finally, the OS waits for the device to finish by again polling it in a
  loop, waiting to see if it is finished (it may then get an error code to
  indicate success or failure).

'''

* This basic protocol has the positive aspect of being simple and working.
* However, there are some inefficiencies and inconveniences involved.
* The first problem you might notice in the protocol is that polling seems
  inefficient; specifically, it wastes a great deal of CPU time just waiting
  for the (potentially slow) device to complete its activity, instead of
  switching to another ready process and thus better utilizing the CPU.

.The crux: How to avoid the costs of polling
****
* How can the OS check device status without frequent polling, and thus lower
  the CPU overhead required to manage the device?
*****

== References

[H17] "Intel Core i7-7700K review: Kaby Lake Debuts for Desktop" by Joel Hruska. January 3, 2017. `www.extremetech.com/extreme/241950-intels-core-i7-7700k-reviewed-kaby-lake-debuts-desktop.`::
* An in-depth review of a recent Intel chipset, including CPUs and the I/O
  subsystem.
