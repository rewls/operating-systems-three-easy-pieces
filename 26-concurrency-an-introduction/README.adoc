= 26 Concurrency: An Introduction
:figure-caption: Figure 26.
:imagesdir: ../images
:source-highlighter: rouge
:tabsize: 8
:toc: left

* Thus far, we have seen the development of the basic abstractions that the OS
  performs.
* We have seen how to take a single physical CPU and turn it into multiple
  *virtual CPUs*, thus enabling the illusion of multiple programs running at
  the same time.
* We have also seen how to create the illusion of a large, private *virtual
  memory* for each process; this abstraction of the *address space* enables each
  program to behave as if it has its own memory when indeed the OS is secretly
  multiplexing address spaces across physical memory (and sometimes, disk).

'''

* In this chapter, we introduce a new abstraction for a single running
  process: that of a *thread*.
* Instead of our classic view of a single point of execution within a program
  (i.e., a single PC where instructions are being fetched from and executed),
  a *multi-threaded* program has more than one point of execution (i.e.,
  multiple PCs, each of which is being fetched and executed from).
* Perhaps another way to think of this is that each thread is very much like a
  separate process, except for one difference: they _share_ the same address
  space and thus can access the same data.

'''

* The state of a single thread is thus very similar to that of a process.
* It has a program counter (PC) that tracks where the program is fetching
  instructions from.
* Each thread has its own private set of registers it uses for computation;
  thus, if there are two threads that are running on a single processor, when
  switching from running one (T1) to running the other (T2), a *context
  switch* must take place.
* The context switch between threads is quite similar to the context switch
  between processes, as the register state of T1 must be saved and the
  register state of T2 restored before running T2.
* With processes, we saved state to a *process control block (PCB)*; now,
  we'll need one or more *thread control blocks (TCBs)* to store the state of
  each thread of a process.
* There is one major difference, though, in the context switch we perform
  between threads as compared to processes: the address space remains the same
  (i.e., there is no need to switch which page table we are using).

'''

* One other major difference between threads and processes concerns the stack.
* In our simple model of the address space of a classic process (which we can
  now call a *single-threaded* process), there is a single stack, usually
  residing at the bottom of the address space (Figure 26.1, left).

'''

* However, in a multi-threaded process, each thread runs independently and of
  course may call into various routines to do whatever work it is doing.
* Instead of a single stack in the address space, there will be one per
  thread.
* Let's say we have a multi-threaded process that has two threads in it; the
  resulting address space looks different (Figure 26.1, right).

.Single-Threaded And Multi-Threaded Address Spaces
image::figure-26-01.png[]

* In this figure, you can see two stacks spread throughout the address space
  of the process.
* Thus, any stack-allocated variables, parameters, return values, and other
  things that we put on the stack will be placed in what is sometimes called
  *thread-local* storage, i.e., the stack of the relevant thread.

'''

* You might also notice how this ruins our beautiful address space layout.
* Before, the stack and heap could grow independently and trouble only arose
  when you ran out of room in the address space.
* Here, we no longer have such a nice situation.
* Fortunately, this is usually OK, as stacks do not generally have to be very
  large (the exception being in programs that make heavy use of recursion).

== 26.1 Why Use Threads?

* Before getting into the details of threads and some of the problems you
  might have in writing multi-threaded programs, let's first answer a more
  simple question.
* Why should you use threads at all?

'''

* As it turns out, there are at least two major reasons you should use
  threads.
* The first is simple: *parallelism*.
* Imagine you are writing a program that performs operations on very large
  arrays, for example, adding two large arrays together, or incrementing the
  value of each element in the array by some amount.
* If you are running on just a single processor, the task is straightforward:
  just perform each operation and be done.
* However, if you are executing the program on a system with multiple
  processors, you have the potential of speeding up this process considerably
  by using the processors to each perform a portion of the work.
* The task of transforming your standard *single-threaded* program into a
  program that does this sort of work on multiple CPUs is called
  *parallelization*, and using a thread per CPU to do this work is a natural
  and typical way to make programs run faster on modern hardware.

'''

* The second reason is a bit more subtle: to avoid blocking program progress
  due to slow I/O.
* Imagine that you are writing a program that performs different types of I/O:
  either waiting to send or receive a message, for an explicit disk I/O to
  complete, or even (implicitly) for a page fault to finish.
* Instead of waiting, your program may wish to do something else, including
  utilizing the CPU to perform computation, or even issuing further I/O
  requests.
* Using threads is a natural way to avoid getting stuck; while one thread in
  your program waits (i.e., is blocked waiting for I/O), the CPU scheduler can
  switch to other threads, which are ready to run and do something useful.
* Threading enables overlap of I/O with other activities within a single
  program, much like multiprogramming did for processes across programs; as a
  result, many modern server-based applications (web servers, database
  management systems, and the like) make use of threads in their
  implementations.

'''

* Of course, in either of the cases mentioned above, you could use multiple
  processes instead of threads.
* However, threads share an address space and thus make it easy to share data,
  and hence are a natural choice when constructing these types of programs.
* Processes are a more sound choice for logically separate tasks where little
  sharing of data structures in memory is needed.

== 26.2 An Example: Thread Creation

* Let's get into some of the details.
* Say we wanted to run a program that creates two threads, each of which does
  some independent work, in this case printing "A" or "B".
* The code is shown in Figure 26.2 (page 4).

:figure-number: 2
.{figure-caption} {figure-number}. Simple Thread Creation Code (`t0.c`)
[,c]
----
include::t0.c[]
----

* The main program creates two threads, each of which will run the function
  `mythread()`, though with different arguments (the string `A` or `B`).
* Once a thread is created, it may start running right away (depending on the
  whims of the scheduler); alternately, it may be put in a "ready" but not
  "running" state and thus not run yet.
* Of course, on a multiprocessor, the threads could even be running at the
  same time, but let's not worry about this possibility quite yet.

'''

* After creating the two threads (let's call them T1 and T2), the main thread
  calls `pthread_join()`, which waits for a particular thread to complete.
* It does so twice, thus ensuring T1 and T2 will run and complete before
  finally allowing the main thread to run again; when it does, it will print
  "main: end" and exit.
* Overall, three threads were employed during this run: the main thread, T1,
  and T2.

'''

* Let us examine the possible execution ordering of this little program.
* In the execution diagram (Figure 26.3, page 5), time increases in the
  downwards direction, and each column shows when a different thread (the main
  one, or Thread 1, or Thread 2) is running.

.Thread Trace (1)
image::figure-26-03.png[]

* Note, however, that this ordering is not the only possible ordering.
* In fact, given a sequence of instructions, there are quite a few, depending
  on which thread the scheduler decides to run at a given point.
* For example, once a thread is created, it may run immediately, which would
  lead to the execution shown in Figure 26.4 (page 5).

.Thread Trace (2)
image::figure-26-04.png[]

* We also could even see "B" printed before "A", if, say, the scheduler
  decided to run Thread 2 first even though Thread 1 was created earlier;
  there is no reason to assume that a thread that is created first will run
  first.
* Figure 26.5 (page 6) shows this final execution ordering, with Thread 2
  getting to strut its stuff before Thread 1.

.Thread Trace (3)
image::figure-26-05.png[]

* As you might be able to see, one way to think about thread creation is that
  it is a bit like making a function call; however, instead of first executing
  the function and then returning to the caller, the system instead creates a
  new thread of execution for the routine that is being called, and it runs
  independently of the caller, perhaps before returning from the create, but
  perhaps much later.
* What runs next is determined by the OS scheduler, and although the scheduler
  likely implements some sensible algorithm, it is hard to know what will run
  at any given moment in time.

'''

* As you also might be able to tell from this example, threads make life
  complicated: it is already hard to tell what will run when!
* Computers are hard enough to understand without concurrency.
* Unfortunately, with concurrency, it simply gets worse.
* Much worse.

== 26.3 Why It Gets Worse: Shared Data

* The simple thread example we showed above was useful in showing how threads
  are created and how they can run in different orders depending on how the
  scheduler decides to run them.
* What it doesn't show you, though, is how threads interact when they access
  shared data.

'''

* Let us imagine a simple example where two threads wish to update a global
  shared variable.
* The code we'll study is in Figure 26.6 (page 7).

:figure-number: 6
.{figure-caption} {figure-number}. Sharing Data: Uh Oh (`t1.c`)
[,c]
----
include::t1.c[]
----

* Here are a few notes about the code.
* First, as Stevens suggests [SR05], we wrap the thread creation and join
  routines to simply exit on failure; for a program as simple as this one, we
  want to at least notice an error occurred (if it did), but not do anything
  very smart about it (e.g., just exit).
* Thus, `Pthread_create()` simply calls `pthread_create()` and makes sure the
  return code is 0; if it isn't, `Pthread_create()` just prints a message and
  exits.

'''

* Second, instead of using two separate function bodies for the worker
  threads, we just use a single piece of code, and pass the thread an argument
  (in this case, a string) so we can have each thread print a different letter
  before its messages.

'''

* Finally, and most importantly, we can now look at what each worker is trying
  to do: add a number to the shared variable counter, and do so 10 million
  times (1e7) in a loop.
* Thus, the desired final result is: 20,000,000.

'''

* We now compile and run the program, to see how it behaves.
* Sometimes, everything works how we might expect:

....
prompt> gcc -o main main.c -Wall -pthread; ./main
main: begin (counter = 0)
A: begin
B: begin
A: done
B: done
main: done with both (counter = 20000000)
....

* Unfortunately, when we run this code, even on a single processor, we don't
  necessarily get the desired result.
* Sometimes, we get:

....
prompt> ./main
main: begin (counter = 0)
A: begin
B: begin
A: done
B: done
main: done with both (counter = 19345221)
....

* Let's try it one more time, just to see if we've gone crazy.
* After all, aren't computers supposed to produce *deterministic* results, as
  you have been taught?!
* Perhaps your professors have been lying to you? (gasp)

....
prompt> ./main
main: begin (counter = 0)
A: begin
B: begin
A: done
B: done
main: done with both (counter = 19221041)
....

* Not only is each run wrong, but also yields a _different_ result!
* A big question remains: why does this happen?

.Tip: Know and use your tools
****
* You should always learn new tools that help you write, debug, and understand
  computer systems.
* Here, we use a neat tool called a *disassembler*.
* When you run a disassembler on an executable, it shows you what assembly
  instructions make up the program.
* For example, if we wish to understand the low-level code to update a counter
  (as in our example), we run `objdump` (Linux) to see the assembly code:
+
....
prompt> objdump -d main
....

* Doing so produces a long listing of all the instructions in the program,
  neatly labeled (particularly if you compiled with the `-g` flag), which
  includes symbol information in the program.
* The `objdump` program is just one of many tools you should learn how to use;
  a debugger like `gdb`, memory profilers like `valgrind` or purify, and of
  course the compiler itself are others that you should spend time to learn
  more about; the better you are at using your tools, the better systems
  you'll be able to build.
****

== 26.4 The Heart Of The Problem: Uncontrolled Scheduling

* To understand why this happens, we must understand the code sequence that
  the compiler generates for the update to `counter`.
* In this case, we wish to simply add a number (1) to `counter`.
* Thus, the code sequence for doing so might look something like this (in
  x86);
+
[source,as]
mov 0x8049a1c, %eax
add $0x1, %eax
mov %eax, 0x8049a1c

'''

* This example assumes that the variable `counter` is located at address
  `0x8049a1c`.
* In this three-instruction sequence, the x86 `mov` instruction is used first
  to get the memory value at the address and put it into register `eax`.
* Then, the add is performed, adding 1 (0x1) to the contents of the `eax`
  register, and finally, the contents of `eax` are stored back into memory at
  the same address.

'''

* Let us imagine one of our two threads (Thread 1) enters this region of code,
  and is thus about to increment counter by one.
* It loads the value of `counter` (let's say it's 50 to begin with) into its
  register `eax`.
* Thus, `eax=50` for Thread 1.
* Then it adds one to the register; thus `eax=51`.
* Now, something unfortunate happens: a timer interrupt goes off; thus, the OS
  saves the state of the currently running thread (its PC, its registers
  including `eax`, etc.) to the thread's TCB.

'''

* Now something worse happens: Thread 2 is chosen to run, and it enters this
  same piece of code.
* It also executes the first instruction, getting the value of `counter` and
  putting it into its `eax` (remember: each thread when running has its own
  private registers; the registers are virtualized by the context-switch code
  that saves and restores them).
* The value of `counter` is still 50 at this point, and thus Thread 2 has
  `eax=50`.
* Let's then assume that Thread 2 executes the next two instructions,
  incrementing `eax` by 1 (thus `eax=51`), and then saving the contents of
  `eax` into `counter` (address `0x8049a1c`).
* Thus, the global variable counter now has the value 51.

'''

* Finally, another context switch occurs, and Thread 1 resumes running.
* Recall that it had just executed the `mov` and `add`, and is now about to
  perform the final `mov` instruction.
* Recall also that `eax=51`.
* Thus, the final `mov` instruction executes, and saves the value to memory;
  the `counter` is set to 51 again.

'''

* Put simply, what has happened is this: the code to increment counter has
  been run twice, but counter, which started at 50, is now only equal to 51.
* A "correct" version of this program should have resulted in the variable
  counter equal to 52.

'''

* Let's look at a detailed execution trace to understand the problem better.
* Assume, for this example, that the above code is loaded at address 100 in
  memory, like the following sequence (note for those of you used to nice,
  RISC-like instruction sets: x86 has variable-length instructions; this `mov`
  instruction takes up 5 bytes of memory, and the `add` only 3):

'''

* With these assumptions, what happens is shown in Figure 26.7 (page 10).
* Assume the counter starts at value 50, and trace through this example to
  make sure you understand what is going on.

.The Problem: Up Close and Personal
image::figure-26-07.png[]

* What we have demonstrated here is called a *race condition* (or, more
  specifically, a *data race*): the results depend on the timing of the code's
  execution.
* With some bad luck (i.e., context switches that occur at untimely points in
  the execution), we get the wrong result.
* In fact, we may get a different result each time; thus, instead of a nice
  *deterministic* computation (which we are used to from computers), we call
  this result *indeterminate*, where it is not known what the output will be
  and it is indeed likely to be different across runs.

'''

* Because multiple threads executing this code can result in a race condition,
  we call this code a *critical section*.
* A critical section is a piece of code that accesses a shared variable (or
  more generally, a shared resource) and must not be concurrently executed by
  more than one thread.

'''

* What we really want for this code is what we call *mutual exclusion*.
* This property guarantees that if one thread is executing within the critical
  section, the others will be prevented from doing so.

'''

* Virtually all of these terms, by the way, were coined by Edsger Dijkstra,
  who was a pioneer in the field and indeed won the Turing Award because of
  this and other work; see his 1968 paper on "Cooperating Sequential
  Processes" [D68] for an amazingly clear description of the problem.
* We'll be hearing more about Dijkstra in this section of the book.

.Tip: Use atomic operations
****
* Atomic operations are one of the most powerful underlying techniques in
  building computer systems, from the computer architecture, to concurrent
  code (what we are studying here), to file systems (which we'll study soon
  enough), database management systems, and even distributed systems [L+93].

'''

* The idea behind making a series of actions *atomic* is simply expressed with
  the phrase "all or nothing"; it should either appear as if all of the
  actions you wish to group together occurred, or that none of them occurred,
  with no in-between state visible.
* Sometimes, the grouping of many actions into a single atomic action is
  called a *transaction*, an idea developed in great detail in the world of
  databases and transaction processing [GR92].

'''

* In our theme of exploring concurrency, we'll be using synchronization
  primitives to turn short sequences of instructions into atomic blocks of
  execution, but the idea of atomicity is much bigger than that, as we will
  see.
* For example, file systems use techniques such as journaling or copy-on-write
  in order to atomically transition their on-disk state, critical for
  operating correctly in the face of system failures.
* If that doesn't make sense, don't worry -- it will, in some future chapter.
****

== 26.5 The Wish For Atomicity

* One way to solve this problem would be to have more powerful instructions
  that, in a single step, did exactly whatever we needed done and thus removed
  the possibility of an untimely interrupt.
* For example, what if we had a super instruction that looked like this:
+
....
memory-add 0x8049a1c, $0x1
....

'''

* Assume this instruction adds a value to a memory location, and the hardware
  guarantees that it executes *atomically*; when the instruction executed, it
  would perform the update as desired.
* It could not be interrupted mid-instruction, because that is precisely the
  guarantee we receive from the hardware: when an interrupt occurs, either the
  instruction has not run at all, or it has run to completion; there is no
  in-between state.
* Hardware can be a beautiful thing, no?

'''

* Atomically, in this context, means "as a unit", which sometimes we take as
  "all or none."
* What we'd like is to execute the three instruction sequence atomically:
+
[source,assembly]
mov 0x8049a1c, %eax
add $0x1, %eax
mov %eax, 0x8049a1c

* As we said, if we had a single instruction to do this, we could just issue
  that instruction and be done.
* But in the general case, we won't have such an instruction.
* Imagine we were building a concurrent B-tree, and wished to update it; would
  we really want the hardware to support an "atomic update of B-tree"
  instruction?
* Probably not, at least in a sane instruction set.

'''

* Thus, what we will instead do is ask the hardware for a few useful
  instructions upon which we can build a general set of what we call
  *synchronization primitives*.
* By using this hardware support, in combination with some help from the
  operating system, we will be able to build multi-threaded code that accesses
  critical sections in a synchronized and controlled manner, and thus reliably
  produces the correct result despite the challenging nature of concurrent
  execution.
* Pretty awesome, right?

'''

* This is the problem we will study in this section of the book.
* It is a wonderful and hard problem, and should make your mind hurt (a bit).
* If it doesn't, then you don't understand!
* Keep working until your head hurts; you then know you're headed in the right
  direction.
* At that point, take a break; we don't want your head hurting too much.

.The crux: How to support synchronization
****
* What support do we need from the hardware in order to build useful
  synchronization primitives?
* What support do we need from the OS?
* How can we build these primitives correctly and efficiently?
* How can programs use them to get the desired results?
****

== 26.6 One More Problem: Waiting For Another

* This chapter has set up the problem of concurrency as if only one type of
  interaction occurs between threads, that of accessing shared variables and
  the need to support atomicity for critical sections.
* As it turns out, there is another common interaction that arises, where one
  thread must wait for another to complete some action before it continues.
* This interaction arises, for example, when a process performs a disk I/O and
  is put to sleep; when the I/O completes, the process needs to be roused from
  its slumber so it can continue.

'''

* Thus, in the coming chapters, we'll be not only studying how to build
  support for synchronization primitives to support atomicity but also for
  mechanisms to support this type of sleeping/waking interaction that is
  common in multi-threaded programs.
* If this doesn't make sense right now, that is OK!
* It will soon enough, when you read the chapter on *condition variables*.
* If it doesn't by then, well, then it is less OK, and you should read that
  chapter again (and again) until it does make sense.

.Aside: Key concurrency terms critical section, race condition, indeterminate, mutual exclusion
****
* These four terms are so central to concurrent code that we thought it worth
  while to call them out explicitly.
* See some of Dijkstra's early work [D65,D68] for more details.

'''

* A *critical section* is a piece of code that accesses a shared resource,
  usually a variable or data structure.
* A *race condition* (or *data race* [NM92]) arises if multiple threads of
  execution enter the critical section at roughly the same time; both attempt
  to update the shared data structure, leading to a surprising (and perhaps
  undesirable) outcome.
* An *indeterminate* program consists of one or more race conditions; the
  output of the program varies from run to run, depending on which threads ran
  when. +
  The outcome is thus not deterministic, something we usually expect from
  computer systems.
* To avoid these problems, threads should use some kind of *mutual exclusion*
  primitives; doing so guarantees that only a single thread ever enters a
  critical section, thus avoiding races, and resulting in deterministic
  program outputs.
****

== 26.7 Summary: Why in OS Class?

* Before wrapping up, one question that you might have is: why are we studying
  this in OS class?
* "History" is the one-word answer; the OS was the first concurrent program,
  and many techniques were created for use within the OS.
* Later, with multi-threaded processes, application programmers also had to
  consider such things.

'''

* For example, imagine the case where there are two processes running.
* Assume they both call `write()` to write to the file, and both wish to
  append the data to the file (i.e., add the data to the end of the file, thus
  increasing its length).
* To do so, both must allocate a new block, record in the inode of the file
  where this block lives, and change the size of the file to reflect the new
  larger size (among other things; we'll learn more about files in the third
  part of the book).
* Because an interrupt may occur at any time, the code that updates these
  shared structures (e.g., a bitmap for allocation, or the file's inode) are
  critical sections; thus, OS designers, from the very beginning of the
  introduction of the interrupt, had to worry about how the OS updates
  internal structures.
* An untimely interrupt causes all of the problems described above.
* Not surprisingly, page tables, process lists, file system structures, and
  virtually every kernel data structure has to be carefully accessed, with the
  proper synchronization primitives, to work correctly.

== References

[D65] "Solution of a problem in concurrent programming control" by E. W. Dijkstra. Communications of the ACM, 8(9):569, September 1965.::
* Pointed to as the first paper of Dijkstra's where he outlines the mutual
  exclusion problem and a solution.
* The solution, however, is not widely used; advanced hardware and OS support
  is needed, as we will see in the coming chapters.

[D68] "Cooperating sequential processes" by Edsger W. Dijkstra. 1968. Available at this site: http://www.cs.utexas.edu/users/EWD/ewd01xx/EWD123.PDF.::
* Dijkstra has an amazing number of his old papers, notes, and thoughts
  recorded (for posterity) on this website at the last place he worked, the
  University of Texas.
* Much of his foundational work, however, was done years earlier while he was
  at the Technische Technische Hogeschool Eindhoven (THE), including this
  famous paper on "cooperating sequential processes", which basically outlines
  all of the thinking that has to go into writing multi-threaded programs.
* Dijkstra discovered much of this while working on an operating system named
  after his school: the "THE" operating system (said "T", "H", "E", and not
  like the word "the").

[GR92] "Transaction Processing: Concepts and Techniques" by Jim Gray and Andreas Reuter. Morgan Kaufmann, September 1992.::
* This book is the bible of transaction processing, written by one of the
  legends of the field, Jim Gray.
* It is, for this reason, also considered Jim Gray's "brain dump", in which he
  wrote down everything he knows about how database management systems work.
* Sadly, Gray passed away tragically a few years back, and many of us lost a
  friend and great mentor, including the co-authors of said book, who were
  lucky enough to interact with Gray during their graduate school years.

[L+93] "Atomic Transactions" by Nancy Lynch, Michael Merritt, William Weihl, Alan Fekete. Morgan Kaufmann, August 1993.::
* A nice text on some of the theory and practice of atomic transactions for
  distributed systems.
* Perhaps a bit formal for some, but lots of good material is found herein.

[NM92] "What Are Race Conditions? Some Issues and Formalizations" by Robert H.  B. Netzer and Barton P. Miller. ACM Letters on Programming Languages and Systems, Volume 1:1, March 1992.::
* An excellent discussion of the different types of races found in concurrent
  programs.
* In this chapter (and the next few), we focus on data races, but later we
  will broaden to discuss general races as well.

[SR05] "Advanced Programming in the UNIX Environment" by W. Richard Stevens and Stephen A. Rago. Addison-Wesley, 2005.::
* As we've said many times, buy this book, and read it, in little chunks,
  preferably before going to bed.
* This way, you will actually fall asleep more quickly; more importantly, you
  learn a little more about how to become a serious UNIX programmer.

== Homework (Simulation)

* This program, `x86.py`, allows you to see how different thread interleavings
  either cause or avoid race conditions.
* See the README for details on how the program works, then answer the
  questions below.

=== Overview

* Welcome to this simulator!
* The idea is to gain familiarity with threads by seeing how they interleave;
  the simulator, `x86.py`, will help you in gaining this understanding.

'''

* The simulator mimicks the execution of short assembly sequences by multiple
  threads.
* Note that the OS code that would run (for example, to perform a context
  switch) is not shown; thus, all you see is the interleaving of the user
  code.

'''

* The assembly code that is run is based on x86, but somewhat simplified.
* In this instruction set, there are four general-purpose registers (%ax, %bx,
  %cx, %dx), a program counter (PC), and a small set of instructions which
  will be enough for our purposes.

'''

* Here is an example code snippet that we will be able to run:

[source,as]
.main
mov 2000, %ax   # get the value at the address
add $1, %ax     # increment it
mov %ax, 2000   # store it back
halt

* The code is easy to understand.
* The first instruction, an x86 "mov", simply loads a value from the address
  specified by 2000 into the register %ax.
* Addresses, in this subset of x86, can take some of the following forms:
** `2000`: the number (2000) is the address
** `(%cx)` : contents of register (in parentheses) forms the address
** `1000(%dx)`: the number + contents of the register form the address
** `10(%ax,%bx)`: the number + reg1 + reg2 forms the address

* To store a value, the same `mov` instruction is used, but this time with the
  arguments reversed, e.g.:

[source,as]
mov %ax, 2000

* The add instruction, from the sequence above, should be clear: it adds an
  immediate value (specified by `$1`) to the register specified in the second
  argument (i.e., `%ax = %ax + 1`).

'''

* Thus, we now can understand the code sequence above: it loads the value at
  address 2000, adds 1 to it, and then stores the value back into address
  2000.

'''

* The fake-ish `halt` instruction just stops running this thread.

'''

* Let's run the simulator and see how this all works!
* Assume the above code sequence is in the file `simple-race.s`.

....
prompt> ./x86.py -p simple-race.s -t 1

       Thread 0
1000 mov 2000, %ax
1001 add $1, %ax
1002 mov %ax, 2000
1003 halt

prompt>
....

* The arguments used here specify the program (`-p`), the number of threads
  (`-t 1`), and the interrupt interval, which is how often a scheduler will be
  woken and run to switch to a different task.
* Because there is only one thread in this example, this interval does not
  matter.

'''

* The output is easy to read: the simulator prints the program counter (here
  shown from 1000 to 1003) and the instruction that gets executed.
* Note that we assume (unrealistically) that all instructions just take up a
  single byte in memory; in x86, instructions are variable-sized and would
  take up from one to a small number of bytes.

'''

* We can use more detailed tracing to get a better sense of how machine state
  changes during the execution:

....
prompt> ./x86.py -p simple-race.s -t 1 -M 2000 -R ax,bx

 2000      ax    bx          Thread 0
    ?       ?     ?
    ?       ?     ?   1000 mov 2000, %ax
    ?       ?     ?   1001 add $1, %ax
    ?       ?     ?   1002 mov %ax, 2000
    ?       ?     ?   1003 halt
....

* Oops!
* Forgot the `-c` flag (which actually computes the answers for you).

....
prompt> ./x86.py -p simple-race.s -t 1 -M 2000 -R ax,bx -c

 2000      ax    bx          Thread 0
    0       0     0
    0       0     0   1000 mov 2000, %ax
    0       1     0   1001 add $1, %ax
    1       1     0   1002 mov %ax, 2000
    1       1     0   1003 halt
....

* By using the `-M` flag, we can trace memory locations (a comma-separated
  list lets you trace more than one, e.g., 2000,3000); by using the `-R` flag
  we can track the values inside specific registers.

'''

* The values on the left show the memory/register contents AFTER the
  instruction on the right has executed.
* For example, after the add instruction, you can see that %ax has been
  incremented to the value 1; after the second mov instruction (at PC=1002),
  you can see that the memory contents at 2000 are now also incremented.

'''

* There are a few more instructions you'll need to know, so let's get to them
  now.
* Here is a code snippet of a loop:

[source,as]
.main
.top
sub  $1,%dx
test $0,%dx
jgte .top
halt

* A few things have been introduced here.
* First is the `test` instruction.
* This instruction takes two arguments and compares them; it then sets
  implicit "condition codes" (kind of like 1-bit registers) which subsequent
  instructions can act upon.

'''

* In this case, the other new instruction is the `jump` instruction (in this
  case, `jgte` which stands for "jump if greater than or equal to").
* This instruction jumps if the second value is greater than or equal to the
  first in the test.

'''

* One last point: to really make this code work, `dx` must be initialized to 1
  or greater.

'''

* Thus, we run the program like this:

....
prompt> ./x86.py -p loop.s -t 1 -a dx=3 -R dx -C -c

   dx   >= >  <= <  != ==        Thread 0
    3   0  0  0  0  0  0
    2   0  0  0  0  0  0  1000 sub  $1,%dx
    2   1  1  0  0  1  0  1001 test $0,%dx
    2   1  1  0  0  1  0  1002 jgte .top
    1   1  1  0  0  1  0  1000 sub  $1,%dx
    1   1  1  0  0  1  0  1001 test $0,%dx
    1   1  1  0  0  1  0  1002 jgte .top
    0   1  1  0  0  1  0  1000 sub  $1,%dx
    0   1  0  1  0  0  1  1001 test $0,%dx
    0   1  0  1  0  0  1  1002 jgte .top
   -1   1  0  1  0  0  1  1000 sub  $1,%dx
   -1   0  0  1  1  1  0  1001 test $0,%dx
   -1   0  0  1  1  1  0  1002 jgte .top
   -1   0  0  1  1  1  0  1003 halt
....

* The `-R dx` flag traces the value of %dx; the `-C` flag traces the values of
  the condition codes that get set by a `test` instruction.
* Finally, the `-a dx=3` flag sets the `%dx` register to the value 3 to start
  with.

'''

* As you can see from the trace, the `sub` instruction slowly lowers the value
  of %dx.
* The first few times `test` is called, only the ">=", ">", and "!=" conditions
  get set.
* However, the last `test` in the trace finds %dx and 0 to be equal, and thus
  the subsequent jump does NOT take place, and the program finally halts.

'''

* Now, finally, we get to a more interesting case, i.e., a race condition with
  multiple threads.
* Let's look at the code first:

....
.main
.top
# critical section
mov 2000, %ax       # get the value at the address
add $1, %ax         # increment it
mov %ax, 2000       # store it back

# see if we're still looping
sub  $1, %bx
test $0, %bx
jgt .top

halt
....

* The code has a critical section which loads the value of a variable (at
  address 2000), then adds 1 to the value, then stores it back.

'''

* The code after just decrements a loop counter (in %bx), tests if it is
  greater than or equal to zero, and if so, jumps back to the top to the
  critical section again.

....
prompt> ./x86.py -p looping-race-nolock.s -t 2 -a bx=1 -M 2000 -c

 2000      bx          Thread 0                Thread 1
    0       1
    0       1   1000 mov 2000, %ax
    0       1   1001 add $1, %ax
    1       1   1002 mov %ax, 2000
    1       0   1003 sub  $1, %bx
    1       0   1004 test $0, %bx
    1       0   1005 jgt .top
    1       0   1006 halt
    1       1   ----- Halt;Switch -----  ----- Halt;Switch -----
    1       1                            1000 mov 2000, %ax
    1       1                            1001 add $1, %ax
    2       1                            1002 mov %ax, 2000
    2       0                            1003 sub  $1, %bx
    2       0                            1004 test $0, %bx
    2       0                            1005 jgt .top
    2       0                            1006 halt
....

* Here you can see each thread ran once, and each updated the shared variable
  at address 2000 once, thus resulting in a count of two there.

'''

* The `Halt;Switch` line is inserted whenever a thread halts and another
  thread must be run.

'''

* One last example: run the same thing above, but with a smaller interrupt
  frequency.
* Here is what that will look like:

....
prompt> ./x86.py -p looping-race-nolock.s -t 2 -a bx=1 -M 2000 -i 2

 2000          Thread 0                Thread 1
    ?
    ?   1000 mov 2000, %ax
    ?   1001 add $1, %ax
    ?   ------ Interrupt ------  ------ Interrupt ------
    ?                            1000 mov 2000, %ax
    ?                            1001 add $1, %ax
    ?   ------ Interrupt ------  ------ Interrupt ------
    ?   1002 mov %ax, 2000
    ?   1003 sub  $1, %bx
    ?   ------ Interrupt ------  ------ Interrupt ------
    ?                            1002 mov %ax, 2000
    ?                            1003 sub  $1, %bx
    ?   ------ Interrupt ------  ------ Interrupt ------
    ?   1004 test $0, %bx
    ?   1005 jgt .top
    ?   ------ Interrupt ------  ------ Interrupt ------
    ?                            1004 test $0, %bx
    ?                            1005 jgt .top
    ?   ------ Interrupt ------  ------ Interrupt ------
    ?   1006 halt
    ?   ----- Halt;Switch -----  ----- Halt;Switch -----
    ?                            1006 halt
....

* As you can see, each thread is interrupt every 2 instructions, as we specify
  via the `-i 2` flag.
* What is the value of memory[2000] throughout this run?
* What should it have been?

'''

* Now let's give a little more information on what can be simulated with this
  program.
* The full set of registers: %ax, %bx, %cx, %dx, and the PC.
* In this version, there is no support for a "stack", nor are there call and
  return instructions.

'''

* The full set of instructions simulated are:

[,as]
----
mov immediate, register     # moves immediate value to register
mov memory, register        # loads from memory into register
mov register, register      # moves value from one register to other
mov register, memory        # stores register contents in memory
mov immediate, memory       # stores immediate value in memory

add immediate, register     # register  = register  + immediate
add register1, register2    # register2 = register2 + register1
sub immediate, register     # register  = register  - immediate
sub register1, register2    # register2 = register2 - register1

test immediate, register    # compare immediate and register (set condition codes)
test register, immediate    # same but register and immediate
test register, register     # same but register and register

jne                         # jump if test'd values are not equal
je                          #                       ... equal
jlt                         #     ... second is less than first
jlte                        #               ... less than or equal
jgt                         #            ... is greater than
jgte                        #               ... greater than or equal

xchg register, memory       # atomic exchange:
                            #   put value of register into memory
                            #   return old contents of memory into reg
                            # do both things atomically

nop                         # no op
----

* Notes:
** 'immediate' is something of the form $number
** 'memory' is of the form 'number' or '(reg)' or 'number(reg)' or
   'number(reg,reg)' (as described above)
* 'register' is one of %ax, %bx, %cx, %dx

* Finally, here are the full set of options to the simulator are available
  with the `-h` flag:

....
Usage: x86.py [options]

Options:
  -h, --help            show this help message and exit
  -s SEED, --seed=SEED  the random seed
  -t NUMTHREADS, --threads=NUMTHREADS
                        number of threads
  -p PROGFILE, --program=PROGFILE
                        source program (in .s)
  -i INTFREQ, --interrupt=INTFREQ
                        interrupt frequency
  -r, --randints        if interrupts are random
  -a ARGV, --argv=ARGV  comma-separated per-thread args (e.g., ax=1,ax=2 sets
                        thread 0 ax reg to 1 and thread 1 ax reg to 2);
                        specify multiple regs per thread via colon-separated
                        list (e.g., ax=1:bx=2,cx=3 sets thread 0 ax and bx and
                        just cx for thread 1)
  -L LOADADDR, --loadaddr=LOADADDR
                        address where to load code
  -m MEMSIZE, --memsize=MEMSIZE
                        size of address space (KB)
  -M MEMTRACE, --memtrace=MEMTRACE
                        comma-separated list of addrs to trace (e.g.,
                        20000,20001)
  -R REGTRACE, --regtrace=REGTRACE
                        comma-separated list of regs to trace (e.g.,
                        ax,bx,cx,dx)
  -C, --cctrace         should we trace condition codes
  -S, --printstats      print some extra stats
  -c, --compute         compute answers for me
....

* Most are obvious.
* Usage of `-r` turns on a random interrupter (from 1 to intfreq as specified
  by `-i`), which can make for more fun during homework problems.
** `-L` specifies where in the address space to load the code.
** `-m` specified the size of the address space (in KB).
** `-S` prints some extra stats
** `-c` is not really used (unlike most simulators in the book); use the
   tracing or condition codes.

* Now you have the basics in place; read the questions at the end of the
  chapter to study this race condition and related issues in more depth.

=== Questions
:example-caption:

.{empty}
====
* Let's examine a simple program, "loop.s".
* First, just read and understand it.
* Then, run it with these arguments (`./x86.py -t 1 -p loop.s -i 100 -R dx`)
* This specifies a single thread, an interrupt every 100 instructions, and
  tracing of register %dx.
* What will `%dx` be during the run?
* Use the `-c` flag to check your answers; the answers, on the left, show the
  value of the register (or memory value) _after_ the instruction on the right
  has run.
====

....
ARG seed 0
ARG numthreads 1
ARG program loop.s
ARG interrupt frequency 100
ARG interrupt randomness False
ARG argv
ARG load address 1000
ARG memsize 128
ARG memtrace
ARG regtrace dx
ARG cctrace False
ARG printstats False
ARG verbose False

   dx          Thread 0
    0
   -1   1000 sub  $1,%dx
   -1   1001 test $0,%dx
   -1   1002 jgte .top
   -1   1003 halt
....

.{empty}
====
* Same code, different flags: (`./x86.py -p loop.s -t 2 -i 100 -a dx=3,dx=3 -R
  dx`)
* This specifies two threads, and initializes each %dx to 3.
* What values will %dx see?
* Run with `-c` to check.
* Does the presence of multiple threads affect your calculations?
* Is there a race in this code?
====

....
ARG seed 0
ARG numthreads 2
ARG program loop.s
ARG interrupt frequency 100
ARG interrupt randomness False
ARG argv dx=3,dx=3
ARG load address 1000
ARG memsize 128
ARG memtrace
ARG regtrace dx
ARG cctrace False
ARG printstats False
ARG verbose False

   dx          Thread 0                Thread 1
    3
    2   1000 sub  $1,%dx
    2   1001 test $0,%dx
    2   1002 jgte .top
    1   1000 sub  $1,%dx
    1   1001 test $0,%dx
    1   1002 jgte .top
    0   1000 sub  $1,%dx
    0   1001 test $0,%dx
    0   1002 jgte .top
   -1   1000 sub  $1,%dx
   -1   1001 test $0,%dx
   -1   1002 jgte .top
   -1   1003 halt
    3   ----- Halt;Switch -----  ----- Halt;Switch -----
    2                            1000 sub  $1,%dx
    2                            1001 test $0,%dx
    2                            1002 jgte .top
    1                            1000 sub  $1,%dx
    1                            1001 test $0,%dx
    1                            1002 jgte .top
    0                            1000 sub  $1,%dx
    0                            1001 test $0,%dx
    0                            1002 jgte .top
   -1                            1000 sub  $1,%dx
   -1                            1001 test $0,%dx
   -1                            1002 jgte .top
   -1                            1003 halt
....

.{empty}
====
* Run this: `./x86.py -p loop.s -t 2 -i 3 -r -R dx -a dx=3,dx=3`
* This makes the interrupt interval small/random; use different seeds (`-s`)
  to see different interleavings.
* Does the interrupt frequency change anything?
====

....
ARG seed 0
ARG numthreads 2
ARG program loop.s
ARG interrupt frequency 3
ARG interrupt randomness True
ARG argv dx=3,dx=3
ARG load address 1000
ARG memsize 128
ARG memtrace
ARG regtrace dx
ARG cctrace False
ARG printstats False
ARG verbose False

   dx          Thread 0                Thread 1
    3
    2   1000 sub  $1,%dx
    2   1001 test $0,%dx
    2   1002 jgte .top
    3   ------ Interrupt ------  ------ Interrupt ------
    2                            1000 sub  $1,%dx
    2                            1001 test $0,%dx
    2                            1002 jgte .top
    2   ------ Interrupt ------  ------ Interrupt ------
    1   1000 sub  $1,%dx
    1   1001 test $0,%dx
    2   ------ Interrupt ------  ------ Interrupt ------
    1                            1000 sub  $1,%dx
    1   ------ Interrupt ------  ------ Interrupt ------
    1   1002 jgte .top
    0   1000 sub  $1,%dx
    1   ------ Interrupt ------  ------ Interrupt ------
    1                            1001 test $0,%dx
    1                            1002 jgte .top
    0   ------ Interrupt ------  ------ Interrupt ------
    0   1001 test $0,%dx
    0   1002 jgte .top
   -1   1000 sub  $1,%dx
    1   ------ Interrupt ------  ------ Interrupt ------
    0                            1000 sub  $1,%dx
   -1   ------ Interrupt ------  ------ Interrupt ------
   -1   1001 test $0,%dx
   -1   1002 jgte .top
    0   ------ Interrupt ------  ------ Interrupt ------
    0                            1001 test $0,%dx
    0                            1002 jgte .top
   -1   ------ Interrupt ------  ------ Interrupt ------
   -1   1003 halt
    0   ----- Halt;Switch -----  ----- Halt;Switch -----
   -1                            1000 sub  $1,%dx
   -1                            1001 test $0,%dx
   -1   ------ Interrupt ------  ------ Interrupt ------
   -1                            1002 jgte .top
   -1                            1003 halt
....

.{empty}
====
* Now, a different program, `looping-race-nolock.s`, which accesses a shared
  variable located at address 2000; we'll call this variable `value`.
* Run it with a single thread to confirm your understanding: `./x86.py -p
  looping-race-nolock.s -t 1 -M 2000`
* What is value (i.e., at memory address `2000`) throughout the run?
* Use `-c` to check.
====

....
ARG seed 0
ARG numthreads 1
ARG program looping-race-nolock.s
ARG interrupt frequency 50
ARG interrupt randomness False
ARG argv
ARG load address 1000
ARG memsize 128
ARG memtrace 2000
ARG regtrace
ARG cctrace False
ARG printstats False
ARG verbose False

 2000          Thread 0
    0
    0   1000 mov 2000, %ax
    0   1001 add $1, %ax
    1   1002 mov %ax, 2000
    1   1003 sub  $1, %bx
    1   1004 test $0, %bx
    1   1005 jgt .top
    1   1006 halt
....

.{empty}
====
* Run with multiple iterations/threads: `./x86.py -p looping-race-nolock.s -t
  2 -a bx=3 -M 2000`
* Why does each thread loop three times?
* What is final value of `value`?
====

....
ARG seed 0
ARG numthreads 2
ARG program looping-race-nolock.s
ARG interrupt frequency 50
ARG interrupt randomness False
ARG argv bx=3
ARG load address 1000
ARG memsize 128
ARG memtrace 2000
ARG regtrace
ARG cctrace False
ARG printstats False
ARG verbose False

 2000          Thread 0                Thread 1
    0
    0   1000 mov 2000, %ax
    0   1001 add $1, %ax
    1   1002 mov %ax, 2000
    1   1003 sub  $1, %bx
    1   1004 test $0, %bx
    1   1005 jgt .top
    1   1000 mov 2000, %ax
    1   1001 add $1, %ax
    2   1002 mov %ax, 2000
    2   1003 sub  $1, %bx
    2   1004 test $0, %bx
    2   1005 jgt .top
    2   1000 mov 2000, %ax
    2   1001 add $1, %ax
    3   1002 mov %ax, 2000
    3   1003 sub  $1, %bx
    3   1004 test $0, %bx
    3   1005 jgt .top
    3   1006 halt
    3   ----- Halt;Switch -----  ----- Halt;Switch -----
    3                            1000 mov 2000, %ax
    3                            1001 add $1, %ax
    4                            1002 mov %ax, 2000
    4                            1003 sub  $1, %bx
    4                            1004 test $0, %bx
    4                            1005 jgt .top
    4                            1000 mov 2000, %ax
    4                            1001 add $1, %ax
    5                            1002 mov %ax, 2000
    5                            1003 sub  $1, %bx
    5                            1004 test $0, %bx
    5                            1005 jgt .top
    5                            1000 mov 2000, %ax
    5                            1001 add $1, %ax
    6                            1002 mov %ax, 2000
    6                            1003 sub  $1, %bx
    6                            1004 test $0, %bx
    6                            1005 jgt .top
    6                            1006 halt
....

.{empty}
====
* Run with random interrupt intervals: `./x86.py -p looping-race-nolock.s -t 2
  -M 2000 -i 4 -r -s 0` with different seeds (`-s 1`, `-s 2`, etc.)
* Can you tell by looking at the thread interleaving what the final value of
  value will be?
* Does the timing of the interrupt matter?
* Where can it safely occur?
* Where not?
* In other words, where is the critical section exactly?
====

....
ARG seed 0
ARG numthreads 2
ARG program looping-race-nolock.s
ARG interrupt frequency 4
ARG interrupt randomness True
ARG argv
ARG load address 1000
ARG memsize 128
ARG memtrace 2000
ARG regtrace
ARG cctrace False
ARG printstats False
ARG verbose False

 2000          Thread 0                Thread 1
    0
    0   1000 mov 2000, %ax
    0   1001 add $1, %ax
    1   1002 mov %ax, 2000
    1   1003 sub  $1, %bx
    1   ------ Interrupt ------  ------ Interrupt ------
    1                            1000 mov 2000, %ax
    1                            1001 add $1, %ax
    2                            1002 mov %ax, 2000
    2                            1003 sub  $1, %bx
    2   ------ Interrupt ------  ------ Interrupt ------
    2   1004 test $0, %bx
    2   1005 jgt .top
    2   ------ Interrupt ------  ------ Interrupt ------
    2                            1004 test $0, %bx
    2                            1005 jgt .top
    2   ------ Interrupt ------  ------ Interrupt ------
    2   1006 halt
    2   ----- Halt;Switch -----  ----- Halt;Switch -----
    2                            1006 halt
....

.{empty}
====
* Now examine fixed interrupt intervals: `./x86.py -p looping-race-nolock.s -a
  bx=1 -t 2 -M 2000 -i 1`
* What will the final value of the shared variable value be?
* What about when you change `-i 2`, `-i 3`, etc.?
* For which interrupt intervals does the program give the "correct" answer?
====

....
ARG seed 0
ARG numthreads 2
ARG program looping-race-nolock.s
ARG interrupt frequency 1
ARG interrupt randomness False
ARG argv bx=1
ARG load address 1000
ARG memsize 128
ARG memtrace 2000
ARG regtrace
ARG cctrace False
ARG printstats False
ARG verbose False

 2000          Thread 0                Thread 1
    0
    0   1000 mov 2000, %ax
    0   ------ Interrupt ------  ------ Interrupt ------
    0                            1000 mov 2000, %ax
    0   ------ Interrupt ------  ------ Interrupt ------
    0   1001 add $1, %ax
    0   ------ Interrupt ------  ------ Interrupt ------
    0                            1001 add $1, %ax
    0   ------ Interrupt ------  ------ Interrupt ------
    1   1002 mov %ax, 2000
    1   ------ Interrupt ------  ------ Interrupt ------
    1                            1002 mov %ax, 2000
    1   ------ Interrupt ------  ------ Interrupt ------
    1   1003 sub  $1, %bx
    1   ------ Interrupt ------  ------ Interrupt ------
    1                            1003 sub  $1, %bx
    1   ------ Interrupt ------  ------ Interrupt ------
    1   1004 test $0, %bx
    1   ------ Interrupt ------  ------ Interrupt ------
    1                            1004 test $0, %bx
    1   ------ Interrupt ------  ------ Interrupt ------
    1   1005 jgt .top
    1   ------ Interrupt ------  ------ Interrupt ------
    1                            1005 jgt .top
    1   ------ Interrupt ------  ------ Interrupt ------
    1   1006 halt
    1   ----- Halt;Switch -----  ----- Halt;Switch -----
    1   ------ Interrupt ------  ------ Interrupt ------
    1                            1006 halt
....

....
ARG seed 0
ARG numthreads 2
ARG program looping-race-nolock.s
ARG interrupt frequency 2
ARG interrupt randomness False
ARG argv bx=1
ARG load address 1000
ARG memsize 128
ARG memtrace 2000
ARG regtrace
ARG cctrace False
ARG printstats False
ARG verbose False

 2000          Thread 0                Thread 1
    0
    0   1000 mov 2000, %ax
    0   1001 add $1, %ax
    0   ------ Interrupt ------  ------ Interrupt ------
    0                            1000 mov 2000, %ax
    0                            1001 add $1, %ax
    0   ------ Interrupt ------  ------ Interrupt ------
    1   1002 mov %ax, 2000
    1   1003 sub  $1, %bx
    1   ------ Interrupt ------  ------ Interrupt ------
    1                            1002 mov %ax, 2000
    1                            1003 sub  $1, %bx
    1   ------ Interrupt ------  ------ Interrupt ------
    1   1004 test $0, %bx
    1   1005 jgt .top
    1   ------ Interrupt ------  ------ Interrupt ------
    1                            1004 test $0, %bx
    1                            1005 jgt .top
    1   ------ Interrupt ------  ------ Interrupt ------
    1   1006 halt
    1   ----- Halt;Switch -----  ----- Halt;Switch -----
    1                            1006 halt
....

....
ARG seed 0
ARG numthreads 2
ARG program looping-race-nolock.s
ARG interrupt frequency 3
ARG interrupt randomness False
ARG argv bx=1
ARG load address 1000
ARG memsize 128
ARG memtrace 2000
ARG regtrace
ARG cctrace False
ARG printstats False
ARG verbose False

 2000          Thread 0                Thread 1
    0
    0   1000 mov 2000, %ax
    0   1001 add $1, %ax
    1   1002 mov %ax, 2000
    1   ------ Interrupt ------  ------ Interrupt ------
    1                            1000 mov 2000, %ax
    1                            1001 add $1, %ax
    2                            1002 mov %ax, 2000
    2   ------ Interrupt ------  ------ Interrupt ------
    2   1003 sub  $1, %bx
    2   1004 test $0, %bx
    2   1005 jgt .top
    2   ------ Interrupt ------  ------ Interrupt ------
    2                            1003 sub  $1, %bx
    2                            1004 test $0, %bx
    2                            1005 jgt .top
    2   ------ Interrupt ------  ------ Interrupt ------
    2   1006 halt
    2   ----- Halt;Switch -----  ----- Halt;Switch -----
    2                            1006 halt
....

.{empty}
====
* Run the same for more loops (e.g., set `-a bx=100`).
* What interrupt intervals (`-i`) lead to a correct outcome?
* Which intervals are surprising?
====

....
include::q8.txt[]
....

.{empty}
====
* One last program: `wait-for-me.s`.
* Run: `./x86.py -p wait-for-me.s -a ax=1,ax=0 -R ax -M 2000`
* This sets the `%ax` register to 1 for thread 0, and 0 for thread 1, and
  watches `%ax` and memory location 2000.
* How should the code behave?
* How is the value at location 2000 being used by the threads?
* What will its final value be?
====

....
ARG seed 0
ARG numthreads 2
ARG program wait-for-me.s
ARG interrupt frequency 50
ARG interrupt randomness False
ARG argv ax=1,ax=0
ARG load address 1000
ARG memsize 128
ARG memtrace 2000
ARG regtrace ax
ARG cctrace False
ARG printstats False
ARG verbose False

 2000      ax          Thread 0                Thread 1
    0       1
    0       1   1000 test $1, %ax
    0       1   1001 je .signaller
    1       1   1006 mov  $1, 2000
    1       1   1007 halt
    1       0   ----- Halt;Switch -----  ----- Halt;Switch -----
    1       0                            1000 test $1, %ax
    1       0                            1001 je .signaller
    1       0                            1002 mov  2000, %cx
    1       0                            1003 test $1, %cx
    1       0                            1004 jne .waiter
    1       0                            1005 halt
....

.{empty}
====
* Now switch the inputs: `./x86.py -p wait-for-me.s -a ax=0,ax=1 -R ax -M
  2000`
* How do the threads behave?
* What is thread 0 doing?
* How would changing the interrupt interval (e.g., `-i 1000`, or perhaps to
  use random intervals) change the trace outcome?
* Is the program efficiently using the CPU?
====

....
ARG seed 0
ARG numthreads 2
ARG program wait-for-me.s
ARG interrupt frequency 50
ARG interrupt randomness False
ARG argv ax=0,ax=1
ARG load address 1000
ARG memsize 128
ARG memtrace 2000
ARG regtrace ax
ARG cctrace False
ARG printstats False
ARG verbose False

 2000      ax          Thread 0                Thread 1
    0       0
    0       0   1000 test $1, %ax
    0       0   1001 je .signaller
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       1   ------ Interrupt ------  ------ Interrupt ------
    0       1                            1000 test $1, %ax
    0       1                            1001 je .signaller
    1       1                            1006 mov  $1, 2000
    1       1                            1007 halt
    1       0   ----- Halt;Switch -----  ----- Halt;Switch -----
    1       0   1002 mov  2000, %cx
    1       0   1003 test $1, %cx
    1       0   1004 jne .waiter
    1       0   1005 halt
....

....
include::q10-i1000.txt[]
....

....
ARG seed 0
ARG numthreads 2
ARG program wait-for-me.s
ARG interrupt frequency 50
ARG interrupt randomness True
ARG argv ax=0,ax=1
ARG load address 1000
ARG memsize 128
ARG memtrace 2000
ARG regtrace ax
ARG cctrace False
ARG printstats False
ARG verbose False

 2000      ax          Thread 0                Thread 1
    0       0
    0       0   1000 test $1, %ax
    0       0   1001 je .signaller
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       0   1004 jne .waiter
    0       0   1002 mov  2000, %cx
    0       0   1003 test $1, %cx
    0       1   ------ Interrupt ------  ------ Interrupt ------
    0       1                            1000 test $1, %ax
    0       1                            1001 je .signaller
    1       1                            1006 mov  $1, 2000
    1       1                            1007 halt
    1       0   ----- Halt;Switch -----  ----- Halt;Switch -----
    1       0   1004 jne .waiter
    1       0   1002 mov  2000, %cx
    1       0   1003 test $1, %cx
    1       0   1004 jne .waiter
    1       0   1005 halt
....
