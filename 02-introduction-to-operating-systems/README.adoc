= 2 Introduction to Operating Systems
:figure-caption: Figure 2.
:source-highlighter: rouge
:tabsize: 8
:toc: left

* If you are taking an undergraduate operating systems course, you should
  already have some idea of what a computer program does when it runs.
* If not, this book (and the corresponding course) is going to be difficult --
  so you should probably stop reading this book, or run to the nearest
  bookstore and quickly consume the necessary background material before
  continuing (both Patt & Patel [PP03] and Bryant & O'Hallaron [BOH10] are
  pretty great books).

'''

* So what happens when a program runs?

'''

* Well, a running program does one very simple thing: it executes
  instructions.
* Many millions (and these days, even billions) of times every second, the
  processor *fetches* an instruction from memory, *decodes* it (i.e., figures
  out which instruction this is), and *executes* it (i.e., it does the thing
  that it is supposed to do, like add two numbers together, access memory,
  check a condition, jump to a function, and so forth).
* After it is done with this instruction, the processor moves on to the next
  instruction, and so on, and so on, until the program finally
  completes{empty}footnote:[Of course, modern processors do many bizarre and
  frightening things underneath the hood to make programs run faster, e.g.,
  executing multiple instructions at once, and even issuing and completing
  them out of order! But that is not our concern here; we are just concerned
  with the simple model most programs assume: that instructions seemingly
  execute one at a time, in an orderly and sequential fashion.].

'''

* Thus, we have just described the basics of the Von Neumann model of
  computing{empty}footnote:[Von Neumann was one of the early pioneers of
  computing systems. He also did pioneering work on game theory and atomic
  bombs, and played in the NBA for six years.  OK, one of those things isn't
  true.].
* Sounds simple, right?
* But in this class, we will be learning that while a program runs, a lot of
  other wild things are going on with the primary goal of making the system
  easy to use.
* There is a body of software, in fact, that is responsible for making it easy
  to run programs (even allowing you to seemingly run many at the same time),
  allowing programs to share memory, enabling programs to interact with
  devices, and other fun stuff like that.
* That body of software is called the *operating system*
  (*OS*)footnote:[Another early name for the OS was the *supervisor* or even
  the *master control program*. Apparently, the latter sounded a little
  overzealous (see the movie Tron for details) and thus, thankfully,
  "operating system" caught on instead.], as it is in charge of making sure
  the system operates correctly and efficiently in an easy-to-use manner.

'''

* The primary way the OS does this is through a general technique that we call
  *virtualization*.
* That is, the OS takes a *physical* resource (such as the processor, or
  memory, or a disk) and transforms it into a more general, powerful, and
  easy-to-use *virtual* form of itself.
* Thus, we sometimes refer to the operating system as a *virtual machine*.

'''

* Of course, in order to allow users to tell the OS what to do and thus make
  use of the features of the virtual machine (such as running a program, or
  allocating memory, or accessing a file), the OS also provides some
  interfaces (APIs) that you can call.
* A typical OS, in fact, exports a few hundred *system calls* that are
  available to applications.
* Because the OS provides these calls to run programs, access memory and
  devices, and other related actions, we also sometimes say that the OS
  provides a *standard library* to applications.

'''

* Finally, because virtualization allows many programs to run (thus sharing
  the CPU), and many programs to concurrently access their own instructions
  and data (thus sharing memory), and many programs to access devices (thus
  sharing disks and so forth), the OS is sometimes known as a *resource
  manager*.
* Each of the CPU, memory, and disk is a *resource* of the system; it is thus
  the operating system's role to *manage* those resources, doing so efficiently
  or fairly or indeed with many other possible goals in mind.
* To understand the role of the OS a little bit better, let's take a look at
  some examples.

.The crux of the problem: How to virtualize resources
****
* One central question we will answer in this book is quite simple: how does
  the operating system virtualize resources?
* This is the crux of our problem.
* Why the OS does this is not the main question, as the answer should be
  obvious: it makes the system easier to use.
* Thus, we focus on the how: what mechanisms and policies are implemented by
  the OS to attain virtualization?
* How does the OS do so efficiently?
* What hardware support is needed?

'''

* We will use the "crux of the problem", in shaded boxes such as this one, as
  a way to call out specific problems we are trying to solve in building an
  operating system.
* Thus, within a note on a particular topic, you may find one or more cruces
  (yes, this is the proper plural) which highlight the problem.
* The details within the chapter, of course, present the solution, or at least
  the basic parameters of a solution.
****

== 2.1 Virtualizing The CPU

* Figure 2.1 depicts our first program.
* It doesn't do much.
* In fact, all it does is call `Spin()`, a function that repeatedly checks the
  time and returns once it has run for a second.
* Then, it prints out the string that the user passed in on the command line,
  and repeats, forever.

:figure-number: 1
.{figure-caption} {figure-number}. Simple Example: Code That Loops And Prints (`cpu.c`)
----
include::cpu.c[]
----

* Let's say we save this file as `cpu.c` and decide to compile and run it on a
  system with a single processor (or *CPU* as we will sometimes call it).
* Here is what we will see:

....
prompt> gcc -o cpu cpu.c -Wall
prompt> ./cpu "A"
A
A
A
A
^C
prompt>
....

'''

* Not too interesting of a run -- the system begins running the program, which
  repeatedly checks the time until a second has elapsed.
* Once a second has passed, the code prints the input string passed in by the
  user (in this example, the letter "A"), and continues.
* Note the program will run forever; by pressing "Control-c" (which on
  UNIX-based systems will terminate the program running in the foreground) we
  can halt the program.

'''

* Now, let's do the same thing, but this time, let's run many different
  instances of this same program.
* Figure 2.2 shows the results of this slightly more complicated example.

:figure-number: 2
.{figure-caption} {figure-number}. Running Many Programs At Once
....
prompt> ./cpu A & ./cpu B & ./cpu C & ./cpu D &
[1] 7353
[2] 7354
[3] 7355
[4] 7356
A
B
D
C
A
B
D
C
A
...
....

* Well, now things are getting a little more interesting.
* Even though we have only one processor, somehow all four of these programs
  seem to be running at the same time!
* How does this magic happen?{empty}footnote:[Note how we ran four processes
  at the same time, by using the `&` symbol. Doing so runs a job in the
  background in the `zsh` shell, which means that the user is able to
  immediately issue their next command, which in this case is another program
  to run. If you're using a different shell (e.g., `tcsh`), it works slightly
  differently; read documentation online for details.]

'''

* It turns out that the operating system, with some help from the hardware, is
  in charge of this *illusion*, i.e., the illusion that the system has a very
  large number of virtual CPUs.
* Turning a single CPU (or a small set of them) into a seemingly infinite
  number of CPUs and thus allowing many programs to seemingly run at once is
  what we call *virtualizing the CPU*, the focus of the first major part of
  this book.

'''

* Of course, to run programs, and stop them, and otherwise tell the OS which
  programs to run, there need to be some interfaces (APIs) that you can use to
  communicate your desires to the OS.
* We'll talk about these APIs throughout this book; indeed, they are the major
  way in which most users interact with operating systems.

'''

* You might also notice that the ability to run multiple programs at once
  raises all sorts of new questions.
* For example, if two programs want to run at a particular time, which
  _should_ run?
* This question is answered by a *policy* of the OS; policies are used in many
  different places within an OS to answer these types of questions, and thus
  we will study them as we learn about the basic *mechanisms* that operating
  systems implement (such as the ability to run multiple programs at once).
* Hence the role of the OS as a *resource manager*.

== 2.2 Virtualizing Memory

* Now let's consider memory.
* The model of *physical memory* presented by modern machines is very simple.
* Memory is just an array of bytes; to *read* memory, one must specify an
  *address* to be able to access the data stored there; to *write* (or
  *update*) memory, one must also specify the data to be written to the given
  address.

'''

* Memory is accessed all the time when a program is running.
* A program keeps all of its data structures in memory, and accesses them
  through various instructions, like loads and stores or other explicit
  instructions that access memory in doing their work.
* Don't forget that each instruction of the program is in memory too; thus
  memory is accessed on each instruction fetch.

:figure-number: 3
.{figure-caption} {figure-number}. A Program That Accesses Memory (`mem.c`)
[,c]
----
include::mem.c[]
----

* Let's take a look at a program (in Figure 2.3) that allocates some memory by
  calling `malloc()`.
* The output of this program can be found here:

....
prompt> ./mem
(2134) address pointed to by p: 0x200000
(2134) p: 1
(2134) p: 2
(2134) p: 3
(2134) p: 4
(2134) p: 5
^C
....

'''

* The program does a couple of things.
* First, it allocates some memory (line a1).
* Then, it prints out the address of the memory (a2), and then puts the number
  zero into the first slot of the newly allocated memory (a3).
* Finally, it loops, delaying for a second and incrementing the value stored
  at the address held in `p`.
* With every print statement, it also prints out what is called the process
  identifier (the PID) of the running program.
* This PID is unique per running process.

'''

* Again, this first result is not too interesting.
* The newly allocated memory is at address `0x200000`.
* As the program runs, it slowly updates the value and prints out the result.

'''

* Now, we again run multiple instances of this same program to see what
  happens (Figure 2.4).
* We see from the example that each running program has allocated memory at
  the same address (0x200000), and yet each seems to be updating the value at
  0x200000 independently!
* It is as if each running program has its own private memory, instead of
  sharing the same physical memory with other running
  programs{empty}footnote:[For this example to work, you need to make sure
  address-space randomization is disabled; randomization, as it turns out, can
  be a good defense against certain kinds of security flaws. Read more about
  it on your own, especially if you want to learn how to break into computer
  systems via stack-smashing attacks. Not that we would recommend such a
  thing...].

:figure-number: 4
.{figure-caption} {figure-number}. Running The Memory Program Multiple Times
....
prompt> ./mem & ./mem &
[1] 24113
[2] 24114
(24113) address pointed to by p: 0x200000
(24114) address pointed to by p: 0x200000
(24113) p: 1
(24114) p: 1
(24114) p: 2
(24113) p: 2
(24113) p: 3
(24114) p: 3
(24113) p: 4
(24114) p: 4
...
....

* Indeed, that is exactly what is happening here as the OS is *virtualizing
  memory*.
* Each process accesses its own private *virtual address space* (sometimes just
  called its *address space*), which the OS somehow maps onto the physical
  memory of the machine.
* A memory reference within one running program does not affect the address
  space of other processes (or the OS itself); as far as the running program
  is concerned, it has physical memory all to itself.
* The reality, however, is that physical memory is a shared resource, managed
  by the operating system.
* Exactly how all of this is accomplished is also the subject of the first
  part of this book, on the topic of *virtualization*.

== References

[BOH10] "Computer Systems: A Programmer's Perspective" by R. Bryant and D.  O'Hallaron. Addison-Wesley, 2010.::
* Another great intro to how computer systems work.
* Has a little bit of overlap with this book -- so if you'd like, you can skip
  the last few chapters of that book, or simply read them to get a different
  perspective on some of the same material.
* After all, one good way to build up your own knowledge is to hear as many
  other perspectives as possible, and then develop your own opinion and
  thoughts on the matter.
* You know, by thinking!

[PP03] "Introduction to Computing Systems: From Bits and Gates to C and Beyond" by Yale N. Patt, Sanjay J. Patel. McGraw-Hill, 2003.::
* One of our favorite intro to computing systems books.
* Starts at transistors and gets you all the way up to C; the early material
  is particularly great.
